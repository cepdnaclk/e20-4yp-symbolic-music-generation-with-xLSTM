{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xLSTM Music Generation - Clean Pipeline\n",
    "\n",
    "This notebook provides a clean, modular approach to generating music with your trained xLSTM model.\n",
    "\n",
    "## Key Fixes from Your Original Code:\n",
    "\n",
    "1. **Memory Issue Fixed**: The problem was `max_length` growing with each iteration\n",
    "   - **Wrong**: `max_length = len(output.split()) + chunk_size` (creates quadratic memory growth)\n",
    "   - **Right**: Use fixed `max_length` OR sliding window context\n",
    "\n",
    "2. **Context Length**: You can use larger context during inference than training\n",
    "   - Trained with 2048 â†’ Can infer with 4096 or more\n",
    "   - But memory grows with contextÂ² in mLSTM\n",
    "\n",
    "3. **Modular Design**: Clean separation of generation and conversion logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello0\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna\")\n",
    "\n",
    "from xlstm_music_generation import MusicGenerator, MIDIConverter, generate_music\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0;8.6;8.9'\n",
    "os.environ['MAX_JOBS'] = '4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/xlstm_lmd_512d_4096ctx_12b/run_20260126-0516\n",
      "\u001b[32m\u001b[1m   â–„â–ˆ    â–ˆâ–„       â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–„â–ˆ        â–„â–ˆ  â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„     â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–„  â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„   â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„      â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„ â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–€  â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–„  â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„     â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ  â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–ˆâ–ˆâ–€   â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–€ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1mâ–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–€â–ˆâ–ˆâ–ˆâ–€  â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€     â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„  â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–€â–€   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–„  â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–„ â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–Œ    â–„ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–€      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–ˆ â–ˆâ–€   â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–€    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–€   â–€â–ˆ   â–ˆâ–€   â–€â–ˆ   â–ˆâ–€    â–ˆâ–ˆâ–ˆ    â–ˆâ–€  \n",
      "\u001b[32m\u001b[1m                            â–€                             â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ                                             \n",
      "\u001b[32m\u001b[22m\n",
      "\u001b[32m\u001b[1mBy Dr. Tristan Behrens\n",
      "\u001b[0m\n",
      "{\n",
      "    \"embedding_dim\": 512,\n",
      "    \"num_blocks\": 12,\n",
      "    \"context_length\": 4096,\n",
      "    \"slstm_at\": [\n",
      "        3,\n",
      "        6,\n",
      "        9\n",
      "    ],\n",
      "    \"mlstm_block\": {\n",
      "        \"mlstm\": {\n",
      "            \"conv1d_kernel_size\": 4,\n",
      "            \"qkv_proj_blocksize\": 4,\n",
      "            \"num_heads\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_block\": {\n",
      "        \"slstm\": {\n",
      "            \"backend\": \"cuda\",\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4,\n",
      "            \"bias_init\": \"powerlaw_blockdependent\"\n",
      "        },\n",
      "        \"feedforward\": {\n",
      "            \"proj_factor\": 1.3,\n",
      "            \"act_fn\": \"gelu\"\n",
      "        }\n",
      "    },\n",
      "    \"vocab_size\": 675\n",
      "}\n",
      "Creating xLSTMLMModel...\n",
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/e20037/.cache/torch_extensions/py311_cu124/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
      "Building extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "Using envvar MAX_JOBS (4) as the number of workers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -Xptxas=\"-v\" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o \n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'\n",
      "ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 32 registers, 440 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'\n",
      "ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 32 registers, 440 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'\n",
      "ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 32 registers, 480 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_86'\n",
      "ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 38 registers, 440 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_86'\n",
      "ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 38 registers, 440 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_86'\n",
      "ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 38 registers, 480 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 38 registers, 440 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 38 registers, 440 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 38 registers, 480 bytes cmem[0]\n",
      "[2/7] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -Xptxas=\"-v\" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o \n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : 0 bytes gmem\n",
      "[3/7] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -Xptxas=\"-v\" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o \n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'\n",
      "ptxas info    : Function properties for _ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 32 registers, 400 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 400 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 400 bytes cmem[0]\n",
      "[4/7] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -Xptxas=\"-v\" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o \n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'\n",
      "ptxas info    : Function properties for _ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 32 registers, 400 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 400 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 400 bytes cmem[0]\n",
      "[5/7] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -Xptxas=\"-v\" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o \n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : 0 bytes gmem\n",
      "[6/7] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -Xptxas=\"-v\" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o \n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'\n",
      "ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 366 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'\n",
      "ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 366 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'\n",
      "ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 368 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'\n",
      "ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 376 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 366 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 366 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 368 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 376 bytes cmem[0]\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_89'\n",
      "ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 366 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_89'\n",
      "ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 366 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_89'\n",
      "ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 368 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_89'\n",
      "ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 376 bytes cmem[0]\n",
      "[7/7] /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/home/e20037/miniconda/envs/xlstm/lib -lcublas -L/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/home/e20037/miniconda/envs/xlstm/lib -lcudart -o slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skipping build step...\n",
      "Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skipping build step...\n",
      "Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2165: FutureWarning: Calling PreTrainedTokenizerFast.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded (context: 4096 tokens)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MODEL_PATH = \"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/lmd_remigen_xlstm/run_20260115-1028\"\n",
    "\n",
    "# Context-4096, embedding-512\n",
    "MODEL_PATH = \"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/xlstm_lmd_512d_4096ctx_12b/run_20260126-0516\"\n",
    "\n",
    "# For short sequences (< 2048 tokens)\n",
    "generator = MusicGenerator(\n",
    "    model_path=MODEL_PATH,\n",
    "    context_length=4096,  # Same as training\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "converter = MIDIConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"s-9 o-42 t-36 i-128 p-166 d-1 v-31 o-45 t-36 i-128 p-166 d-2 v-31 b-1 s-9 o-0 t-36 i-12 p-65 d-12 v-31 p-57 d-12 v-31 i-27 p-65 d-3 v-26 p-60 d-2 v-25 p-57 d-3 v-25 p-53 d-3 v-30 i-33 p-29 d-4 v-31 i-48 p-65 d-14 v-31 p-57 d-42 v-27 i-88 p-77 d-13 v-26 p-69 d-13 v-24 i-128 p-198 d-2 v-20 p-177 d-4 v-26 p-170 d-2 v-22 p-164 d-5 v-31 o-6 t-36 i-27 p-65 d-8 v-26 p-60 d-7 v-25 p-57 d-7 v-25 p-53 d-6 v-29 i-28 p-53 d-2 v-31 i-33 p-29 d-5 v-31 i-45 p-65 d-2 v-31 i-128 p-198 d-2 v-15 p-170 d-2 v-15 o-9 t-36 i-28 p-53 d-2 v-31 i-45 p-65 d-2 v-29 i-128 p-170 d-2 v-18 o-12 t-36 i-28 p-53 d-2 v-31 i-33 p-26 d-5 v-31 i-45 p-65 d-2 v-27 i-128 p-198 d-2 v-20 p-170 d-2 v-20 p-166 d-3 v-31 p-164 d-6 v-31 o-18 t-36 i-12 p-64 d-12 v-31 p-57 d-12 v-31 i-27 p-65 d-3 v-27 p-60 d-2 v-26 p-57 d-3 v-25 p-53 d-3 v-28 i-28 p-53 d-2 v-31 i-33 p-24 d-5 v-31 i-45 p-65 d-2 v-29 i-48 p-64 d-15 v-28 i-88 p-76 d-12 v-24 p-69 d-12 v-23 i-128 p-198 d-2 v-14 p-170 d-2 v-15 o-21 t-36 i-128 p-170 d-2 v-15 o-24 t-36 i-33 p-29 d-11 v-31 i-128 p-198 d-3 v-19 p-170 d-2 v-21 p-164 d-6 v-31 o-30 t-36 i-27 p-65 d-7 v-28 p-60 d-7 v-27 p-57 d-7 v-27 p-53 d-7 v-29 i-28 p-53 d-2 v-31 i-45 p-65 d-2 v-30 i-128 p-198 d-2 v-13 p-170 d-2 v-14 o-33 t-36 i-128 p-170 d-2 v-16 o-36 t-36 i-12 p-62 d-7 v-31 p-57 d-8 v-31 i-28 p-50 d-2 v-31 i-33 p-26 d-5 v-31 i-45 p-62 d-2 v-28 i-48 p-62 d-12 v-29 i-88 p-74 d-7 v-26 p-69 d-7 v-23 i-128 p-198 d-2 v-20 p-170 d-2 v-20 p-166 d-3 v-31 p-164 d-5 v-31 o-42 t-36 i-27 p-65 d-3 v-26 p-60 d-1 v-25 p-57 d-3 v-25 p-53 d-3 v-28 i-28 p-48 d-2 v-31 i-33 p-24 d-6 v-31 i-45 p-60 d-2 v-26 i-128 p-198 d-1 v-16 p-170 d-2 v-15 o-45 t-36 i-128 p-198 d-1 v-18 p-170 d-2 v-16 b-1 s-9 o-0 t-36 i-12 p-65 d-13 v-31 p-57 d-12 v-31 i-27 p-65 d-2 v-25 p-60 d-2 v-25 p-57 d-2 v-24 p-53 d-3 v-27 i-33 p-29 d-4 v-31 i-48 p-65 d-14 v-31 i-88 p-77 d-13 v-28 p-69 d-13 v-24 i-128 p-198 d-2 v-18 p-170 d-2 v-21 p-164 d-4 v-31 o-6 t-36 i-27 p-65 d-8 v-26 p-60 d-7 v-26 p-57 d-7 v-25 p-53 d-7 v-27 i-28 p-53 d-1 v-31 i-33 p-29 d-5 v-31 i-45 p-65 d-1 v-28 i-128 p-198 d-2 v-12 p-170 d-2 v-12 o-9 t-36 i-28 p-53 d-2 v-31 i-45 p-65 d-2 v-27 i-128 p-170 d-2 v-16 o-12 t-36 i-28 p-53 d-2 v-31 i-33 p-26 d-4 v-31 i-45 p-65 d-2 v-26 i-128 p-198 d-2 v-19 p-170 d-2 v-19 p-166 d-3 v-31 p-164 d-5 v-31 o-18 t-36 i-12 p-64 d-13 v-31 p-57 d-12 v-31 i-27 p-65 d-3 v-26 p-60 d-3 v-26 p-57 d-2 v-25 p-53 d-3 v-26 i-28 p-53 d-2 v-31 i-33 p-24 d-6 v-31 i-45 p-65 d-2 v-26 i-48 p-64 d-15 v-30 i-88 p-76 d-13 v-31 p-69 d-12 v-28 i-128 p-198 d-2 v-13 p-170 d-2 v-13 o-21 t-36 i-128 p-170 d-2 v-16 o-24 t-36 i-33 p-29 d-11 v-31 i-128 p-198 d-2 v-18 p-170 d-2 v-19 p-164 d-4 v-31 o-30 t-36 i-27 p-65 d-2 v-26 p-60 d-2 v-26 p-57 d-3 v-25 p-53 d-3 v-27 i-28 p-53 d-2 v-31 i-45 p-65 d-2 v-26 i-128 p-198 d-2 v-15 p-170 d-2 v-14 o-33 t-36 i-128 p-170 d-2 v-16 o-36 t-36 i-12 p-62 d-7 v-31 p-57 d-8 v-31 i-28 p-50 d-2 v-31 i-33 p-26 d-5 v-31 i-45 p-62 d-2 v-27 i-88 p-74 d-7 v-28 p-69 d-7 v-23 i-128 p-198 d-2 v-20 p-170 d-2 v-20 p-166 d-3 v-31 p-164 d-4 v-31 o-37 t-36 i-48 p-62 d-12 v-30 o-42 t-36 i-27 p-65 d-3 v-25 p-60 d-3 v-25 p-57 d-3 v-24 p-53 d-3 v-27 i-28 p-48 d-2 v-31 i-33 p-24 d-5 v-31 i-45 p-60 d-2 v-26 i-128 p-198 d-2 v-17 p-170 d-2 v-14 o-45 t-36 i-128 p-198 d-2 v-19 p-170 d-2 v-15 b-1 s-9 o-0 t-36 i-12 p-65 d-13 v-31 p-57 d-13 v-31 i-27 p-65 d-3 v-25 p-60 d-2 v-25 p-57 d-2 v-24 p-53 d-3 v-25 i-33 p-29 d-4 v-31 i-88 p-77 d-13 v-28 p-69 d-13 v-24 i-128 p-198 d-2 v-18 p-170 d-2 v-20 p-164 d-4 v-31 o-1 t-36 i-48 p-65 d-13 v-31 o-6 t-36 i-27 p-65 d-8 v-27 p-60 d-7 v-27 p-57 d-8 v-26 p-53 d-7 v-29 i-28 p-53 d-1 v-31 i-33 p-29 d-5 v-31 i-45 p-65 d-1 v-30 i-128 p-198 d-1 v-16 p-170 d-2 v-13 o-9 t-36 i-28 p-53 d-2 v-31 i-45 p-65 d-2 v-25 i-128 p-170 d-2 v-15 o-12 t-36 i-28 p-53 d-2 v-31 i-33 p-26 d-5 v-31 i-45 p-65 d-2 v-25 i-128 p-198 d-2 v-20 p-170 d-2 v-20 p-166 d-4 v-31 p-164 d-4 v-31 o-18 t-36 i-12 p-64 d-13 v-31 p-57 d-13 v-31 i-27 p-65 d-3 v-26 p-60 d-3 v-26 p-57 d-3 v-25 p-53 d-3 v-27 i-28 p-53 d-1 v-31 i-33 p-24 d-4 v-31 i-45 p-65 d-1 v-27 i-48 p-64 d-15 v-30 i-88 p-76 d-13 v-25 p-69 d-12 v-24 i-128 p-198 d-2 v-15 p-170 d-2 v-14 o-21 t-36 i-128 p-170 d-2 v-15 o-24 t-36 i-33 p-29 d-12 v-31 i-128 p-198 d-2 v-18 p-170 d-2 v-19 p-164 d-4 v-31 o-30 t-36 i-27 p-65 d-3 v-27 p-60 d-3 v-27 p-57 d-3 v-25 p-53 d-3 v-28 i-28 p-53 d-2 v-31 i-45 p-65 d-2 v-26 i-128 p-198 d-2 v-13 p-170 d-2 v-16 o-33 t-36 i-128 p-170 d-1 v-17 o-36 t-36 i-12 p-62 d-5 v-31 p-57 d-6 v-31 i-28 p-48 d-2 v-31 i-33 p-26 d-6 v-31 i-45 p-60 d-2 v-21 i-48 p-62 d-11 v-27 i-88 p-74 d-6 v-30 p-69 d-6 v-23 i-128 p-198 d-2 v-18 p-170 d-2 v-18 p-166 d-4 v-31 p-164 d-5 v-31 o-39 t-36 i-128 p-170 d-1 v-17 o-42 t-36 i-27 p-65 d-2 v-25 p-60 d-3 v-24 p-57 d-2 v-23 p-53 d-3 v-27 i-28 p-53 d-2 v-31 i-33 p-24 d-3 v-31 i-45 p-65 d-2 v-24 i-128 p-198 d-2 v-17 p-172 d-2 v-19 o-45 t-36 i-128 p-198 d-2 v-18 b-1 s-9 o-0 t-36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Long generation (bar-aware chunking)...\n",
      "   Target: 64 bars\n",
      "   Strategy: Generate 2-3 bars per iteration, cut at b-1\n",
      "\n",
      "ðŸ“ Iteration 1/50\n",
      "   Context: 996 tokens (4 bars)\n",
      "   Generated: 600 tokens\n",
      "   Kept (complete bars): 436 tokens (1 bars)\n",
      "   Total: 1432 tokens (5 bars)\n",
      "\n",
      "ðŸ“ Iteration 2/50\n",
      "   Context: 1432 tokens (5 bars)\n",
      "   Generated: 600 tokens\n",
      "   Kept (complete bars): 457 tokens (1 bars)\n",
      "   Total: 1889 tokens (6 bars)\n",
      "\n",
      "ðŸ“ Iteration 3/50\n",
      "   Context: 1889 tokens (6 bars)\n",
      "   Generated: 597 tokens\n",
      "   Kept (complete bars): 498 tokens (1 bars)\n",
      "   Total: 2387 tokens (7 bars)\n",
      "\n",
      "ðŸ“ Iteration 4/50\n",
      "   Context: 2387 tokens (7 bars)\n",
      "   Generated: 547 tokens\n",
      "   Kept (complete bars): 536 tokens (1 bars)\n",
      "   Total: 2923 tokens (8 bars)\n",
      "\n",
      "ðŸ“ Iteration 5/50\n",
      "   Context: 2923 tokens (8 bars)\n",
      "   Generated: 504 tokens\n",
      "   Kept (complete bars): 476 tokens (3 bars)\n",
      "   Total: 3399 tokens (11 bars)\n",
      "\n",
      "ðŸ“ Iteration 6/50\n",
      "   Context: 3399 tokens (11 bars)\n",
      "   Generated: 543 tokens\n",
      "   Kept (complete bars): 427 tokens (2 bars)\n",
      "   Total: 3826 tokens (13 bars)\n",
      "\n",
      "ðŸ“ Iteration 7/50\n",
      "   Context: 3400 tokens (11 bars)\n",
      "   Generated: 431 tokens\n",
      "   Kept (complete bars): 302 tokens (1 bars)\n",
      "   Total: 4128 tokens (14 bars)\n",
      "\n",
      "ðŸ“ Iteration 8/50\n",
      "   Context: 3400 tokens (11 bars)\n",
      "   Generated: 423 tokens\n",
      "   Kept (complete bars): 294 tokens (1 bars)\n",
      "   Total: 4422 tokens (15 bars)\n",
      "\n",
      "ðŸ“ Iteration 9/50\n",
      "   Context: 3400 tokens (11 bars)\n",
      "   Generated: 449 tokens\n",
      "   Kept (complete bars): 330 tokens (1 bars)\n",
      "   Total: 4752 tokens (16 bars)\n",
      "\n",
      "ðŸ“ Iteration 10/50\n",
      "   Context: 3400 tokens (12 bars)\n",
      "   Generated: 509 tokens\n",
      "   Kept (complete bars): 428 tokens (2 bars)\n",
      "   Total: 5180 tokens (18 bars)\n",
      "\n",
      "ðŸ“ Iteration 11/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 491 tokens\n",
      "   Kept (complete bars): 350 tokens (1 bars)\n",
      "   Total: 5530 tokens (19 bars)\n",
      "\n",
      "ðŸ“ Iteration 12/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 542 tokens\n",
      "   Kept (complete bars): 445 tokens (2 bars)\n",
      "   Total: 5975 tokens (21 bars)\n",
      "\n",
      "ðŸ“ Iteration 13/50\n",
      "   Context: 3400 tokens (14 bars)\n",
      "   Generated: 573 tokens\n",
      "   Kept (complete bars): 364 tokens (2 bars)\n",
      "   Total: 6339 tokens (23 bars)\n",
      "\n",
      "ðŸ“ Iteration 14/50\n",
      "   Context: 3400 tokens (14 bars)\n",
      "   Generated: 566 tokens\n",
      "   Kept (complete bars): 307 tokens (1 bars)\n",
      "   Total: 6646 tokens (24 bars)\n",
      "\n",
      "ðŸ“ Iteration 15/50\n",
      "   Context: 3400 tokens (15 bars)\n",
      "   Generated: 585 tokens\n",
      "   Kept (complete bars): 291 tokens (1 bars)\n",
      "   Total: 6937 tokens (25 bars)\n",
      "\n",
      "ðŸ“ Iteration 16/50\n",
      "   Context: 3400 tokens (14 bars)\n",
      "   Generated: 525 tokens\n",
      "   Kept (complete bars): 416 tokens (1 bars)\n",
      "   Total: 7353 tokens (26 bars)\n",
      "\n",
      "ðŸ“ Iteration 17/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 474 tokens\n",
      "   Kept (complete bars): 289 tokens (1 bars)\n",
      "   Total: 7642 tokens (27 bars)\n",
      "\n",
      "ðŸ“ Iteration 18/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 497 tokens\n",
      "   Kept (complete bars): 301 tokens (1 bars)\n",
      "   Total: 7943 tokens (28 bars)\n",
      "\n",
      "ðŸ“ Iteration 19/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 504 tokens\n",
      "   Kept (complete bars): 272 tokens (1 bars)\n",
      "   Total: 8215 tokens (29 bars)\n",
      "\n",
      "ðŸ“ Iteration 20/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 529 tokens\n",
      "   Kept (complete bars): 285 tokens (1 bars)\n",
      "   Total: 8500 tokens (30 bars)\n",
      "\n",
      "ðŸ“ Iteration 21/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 476 tokens\n",
      "   Kept (complete bars): 316 tokens (1 bars)\n",
      "   Total: 8816 tokens (31 bars)\n",
      "\n",
      "ðŸ“ Iteration 22/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "   Generated: 537 tokens\n",
      "   Kept (complete bars): 445 tokens (2 bars)\n",
      "   Total: 9261 tokens (33 bars)\n",
      "\n",
      "ðŸ“ Iteration 23/50\n",
      "   Context: 3400 tokens (13 bars)\n",
      "âš ï¸  No complete bar (b-1) found in new tokens, stopping\n",
      "\n",
      "âœ“ Generation complete!\n",
      "   Final: 9261 tokens, 33 bars\n"
     ]
    }
   ],
   "source": [
    "result = generator.generate_long(\n",
    "    prompt=prompt,\n",
    "    temperature=0.8,\n",
    "    target_bars=64,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ— Decoding error: AssertionError: \n",
      "Success: False\n"
     ]
    }
   ],
   "source": [
    "# Try decoding WITHOUT cleaning\n",
    "success = converter.tokens_to_midi(result['tokens'], \"./output/long_clean.mid\", clean=False)\n",
    "print(f\"Success: {success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "success = converter.tokens_to_midi(result['tokens'], \"./output/long_clean.mid\", clean=True)\n",
    "print(f\"Success: {success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7882\n",
      "Last 30 tokens: ['p-163', 'd-1', 'v-26', 'o-42', 't-27', 'i-2', 'p-59', 'd-3', 'v-25', 'i-128', 'p-174', 'd-1', 'v-21', 'o-45', 't-27', 'i-2', 'p-59', 'd-6', 'v-25', 'i-128', 'p-183', 'd-1', 'v-17', 'p-174', 'd-1', 'v-21', 'p-163', 'd-1', 'v-26', 'b-1']\n",
      "Ends with b-1? True\n"
     ]
    }
   ],
   "source": [
    "# Debug the last tokens\n",
    "tokens_list = result['tokens'].split()\n",
    "print(f\"Total: {len(tokens_list)}\")\n",
    "print(f\"Last 30 tokens: {tokens_list[-30:]}\")\n",
    "print(f\"Ends with b-1? {tokens_list[-1] == 'b-1'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Generating...\n",
      "   Prompt: s-9 o-0 t-35...\n",
      "   Max tokens: 2000\n",
      "   Temperature: 0.9\n",
      "âœ“ Generated 2000 tokens (7 bars)\n"
     ]
    }
   ],
   "source": [
    "# Try single-shot generation with larger max_length\n",
    "result = generator.generate(\n",
    "    prompt=\"s-9 o-0 t-35\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=2000,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: ./output/sample_8_ct4096-len100.mid\n",
      "Generated 1999 tokens, 15 bars\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "output_path = \"./output/sample_8_ct4096-len1000.mid\"\n",
    "success = converter.tokens_to_midi(result['tokens'], output_path, clean=True)\n",
    "\n",
    "if success:\n",
    "    print(f\"âœ“ Saved: {output_path}\")\n",
    "    print(f\"Generated {result['num_tokens']} tokens, {result['bars']} bars\")\n",
    "else:\n",
    "    print(\"Decoding failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 3056\n",
      "Last 30 tokens: ['d-3', 'v-12', 'd-3', 'v-12', 'i-128', 'p-166', 'd-3', 'v-12', 'b-1', 'd-3', 'v-12', 'd-3', 'v-12', 'd-2', 'd-3', 'd-14', 'd-2', 'd-2', 'd-2', 'p-77', 'd-2', 'v-12', 'o-6', 't-33', 'i-34', 'v-8', 'd-2', 'd-3', 'd-2', 'd-3']\n"
     ]
    }
   ],
   "source": [
    "# Debug: see what token is causing the error\n",
    "tokens = result['tokens'].split()\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(f\"Last 30 tokens: {tokens[-30:]}\")\n",
    "\n",
    "# Find incomplete triplets\n",
    "for i, token in enumerate(tokens[-30:], start=len(tokens)-30):\n",
    "    if token.startswith('p-'):\n",
    "        if i+1 >= len(tokens) or not tokens[i+1].startswith('d-'):\n",
    "            print(f\"Incomplete at {i}: {token} (no duration)\")\n",
    "        elif i+2 >= len(tokens) or not tokens[i+2].startswith('v-'):\n",
    "            print(f\"Incomplete at {i}: {token} {tokens[i+1]} (no velocity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Generate Short Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Generating...\n",
      "   Prompt: s-9 o-0 t-38...\n",
      "   Max tokens: 1000\n",
      "   Temperature: 0.8\n",
      "âœ“ Generated 1000 tokens (8 bars)\n",
      "\n",
      "Generated 1000 tokens, 8 bars\n",
      "Saved to: ./output/test_song.mid\n"
     ]
    }
   ],
   "source": [
    "# Simple generation\n",
    "result = generator.generate(\n",
    "    prompt=\"s-9 o-0 t-38\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=1000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {result['num_tokens']} tokens, {result['bars']} bars\")\n",
    "\n",
    "# Convert to MIDI\n",
    "output_path = \"./output/test_song.mid\"\n",
    "converter.tokens_to_midi(result['tokens'], output_path)\n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Generate Long Piece (Chunked)\n",
    "\n",
    "This uses **sliding window** approach to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/lmd_remigen_xlstm/run_20260115-1028\n",
      "\u001b[32m\u001b[1m   â–„â–ˆ    â–ˆâ–„       â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–„â–ˆ        â–„â–ˆ  â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„     â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–„  â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„   â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„      â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„ â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–€  â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–„  â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„     â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ  â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–ˆâ–ˆâ–€   â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–€ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1mâ–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–€â–ˆâ–ˆâ–ˆâ–€  â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€     â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„  â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–€â–€   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–„  â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–„ â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–Œ    â–„ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–€      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–ˆ â–ˆâ–€   â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–€    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–€   â–€â–ˆ   â–ˆâ–€   â–€â–ˆ   â–ˆâ–€    â–ˆâ–ˆâ–ˆ    â–ˆâ–€  \n",
      "\u001b[32m\u001b[1m                            â–€                             â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ                                             \n",
      "\u001b[32m\u001b[22m\n",
      "\u001b[32m\u001b[1mBy Dr. Tristan Behrens\n",
      "\u001b[0m\n",
      "{\n",
      "    \"num_blocks\": 12,\n",
      "    \"embedding_dim\": 256,\n",
      "    \"mlstm_block\": {\n",
      "        \"mlstm\": {\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_block\": {\n",
      "        \"slstm\": {\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_at\": [\n",
      "        3,\n",
      "        6,\n",
      "        9\n",
      "    ],\n",
      "    \"context_length\": 4096,\n",
      "    \"vocab_size\": 675\n",
      "}\n",
      "Creating xLSTMLMModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2165: FutureWarning: Calling PreTrainedTokenizerFast.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded (context: 4096 tokens)\n",
      "ðŸŽµ Long generation (chunked)...\n",
      "   Target: 64 bars\n",
      "   Chunk size: 1024 tokens\n",
      "\n",
      "ðŸ“ Iteration 1/2\n",
      "   Context: 26 tokens\n",
      "   Added: 1024 tokens (3 bars)\n",
      "   Total: 1050 tokens (4 bars)\n",
      "\n",
      "ðŸ“ Iteration 2/2\n",
      "   Context: 1050 tokens\n",
      "   Added: 1023 tokens (4 bars)\n",
      "   Total: 2073 tokens (8 bars)\n",
      "\n",
      "âœ“ Generation complete!\n",
      "   Final: 2073 tokens, 8 bars\n",
      "\n",
      "Saved 8 bars to: ./output/long_song.mid\n"
     ]
    }
   ],
   "source": [
    "# For long generation, use larger context\n",
    "long_generator = MusicGenerator(\n",
    "    model_path=MODEL_PATH,\n",
    "    context_length=4096,  # Larger than training\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "result = long_generator.generate_long(\n",
    "    prompt=\"s-9 o-30 t-33 i-128 p-176 d-6 v-23 o-36 t-33 i-128 p-173 d-6 v-23 o-42 t-33 i-128 p-171 d-6 v-23 b-1 s-9 o-0 t-33 i-4 p-81 d-25\",\n",
    "    temperature=0.8,\n",
    "    target_bars=64,       # Generate 64 bars\n",
    "    chunk_tokens=1024,    # 1024 new tokens per iteration\n",
    "    max_iterations=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save\n",
    "output_path = \"./output/long_song.mid\"\n",
    "converter.tokens_to_midi(result['tokens'], output_path)\n",
    "print(f\"\\nSaved {result['bars']} bars to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: 3509 tokens\n",
      "Last 20 cleaned: ['i-128', 'o-47', 'p-66', 'd-2', 'v-22', 'b-1', 'o-47', 'b-1', 'o-2', 'o-47', 'b-1', 'o-47', 'b-1', 'o-47', 'o-47', 'i-37', 'p-27', 'd-5', 'i-128', 'o-47']\n",
      "Error: AssertionError: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3928866/513666804.py\", line 7, in <module>\n",
      "    midi_obj = converter.decoder.decode_from_token_str_list(cleaned.split())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/midiprocessor/midi_decoding.py\", line 195, in decode_from_token_str_list\n",
      "    midi_obj = self.decode_from_token_list(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/midiprocessor/midi_decoding.py\", line 244, in decode_from_token_list\n",
      "    return enc_remigen_utils.generate_midi_obj_from_remigen_token_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/midiprocessor/enc_remigen_utils.py\", line 250, in generate_midi_obj_from_remigen_token_list\n",
      "    assert last_item_type == const.DURATION_ABBR\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "# Add detailed error reporting\n",
    "cleaned = converter.clean_tokens(result['tokens'])\n",
    "print(f\"Cleaned: {len(cleaned.split())} tokens\")\n",
    "print(f\"Last 20 cleaned: {cleaned.split()[-20:]}\")\n",
    "\n",
    "try:\n",
    "    midi_obj = converter.decoder.decode_from_token_str_list(cleaned.split())\n",
    "    print(\"âœ“ Decoding successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Batch Generation with Different Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [0.5, 0.8, 1.0, 1.2]\n",
    "output_dir = Path(\"./output/temp_comparison\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = generator.generate(\n",
    "        prompt=\"s-9 o-0 t-35\",\n",
    "        temperature=temp,\n",
    "        max_tokens=2000,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    midi_path = output_dir / f\"temp_{temp:.1f}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], str(midi_path))\n",
    "    print(f\"âœ“ Saved: {midi_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Simple API (One Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 songs with one function call\n",
    "outputs = generate_music(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_songs=5,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    output_dir=\"./output/batch\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(outputs)} songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Long Mode with Simple API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate long pieces\n",
    "outputs = generate_music(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_songs=2,\n",
    "    temperature=0.8,\n",
    "    output_dir=\"./output/long_batch\",\n",
    "    long_mode=True,\n",
    "    target_bars=64\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(outputs)} long songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Generated MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: single_shot_test.mid\n",
      "Duration: 28.80s\n",
      "Instruments: 6\n",
      "Total notes: 457\n",
      "  - 27: 113 notes (Program 27)\n",
      "  - 35: 113 notes (Program 35)\n",
      "  - 52: 83 notes (Program 52)\n",
      "  - 53: 45 notes (Program 53)\n",
      "  - 54: 46 notes (Program 54)\n",
      "  - 128: 57 notes (Drums)\n",
      "\n",
      "File: long_song.mid\n",
      "Duration: 33.30s\n",
      "Instruments: 5\n",
      "Total notes: 507\n",
      "  - 4: 57 notes (Program 4)\n",
      "  - 24: 158 notes (Program 24)\n",
      "  - 33: 54 notes (Program 33)\n",
      "  - 49: 59 notes (Program 49)\n",
      "  - 128: 179 notes (Drums)\n",
      "\n",
      "File: test_song.mid\n",
      "Duration: 14.20s\n",
      "Instruments: 4\n",
      "Total notes: 244\n",
      "  - 16: 40 notes (Program 16)\n",
      "  - 25: 170 notes (Program 25)\n",
      "  - 35: 30 notes (Program 35)\n",
      "  - 128: 4 notes (Drums)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "\n",
    "def analyze_midi(midi_path):\n",
    "    midi = pretty_midi.PrettyMIDI(str(midi_path))\n",
    "    \n",
    "    print(f\"File: {midi_path.name}\")\n",
    "    print(f\"Duration: {midi.get_end_time():.2f}s\")\n",
    "    print(f\"Instruments: {len(midi.instruments)}\")\n",
    "    print(f\"Total notes: {sum(len(inst.notes) for inst in midi.instruments)}\")\n",
    "    \n",
    "    for inst in midi.instruments:\n",
    "        inst_type = \"Drums\" if inst.is_drum else f\"Program {inst.program}\"\n",
    "        print(f\"  - {inst.name}: {len(inst.notes)} notes ({inst_type})\")\n",
    "    print()\n",
    "\n",
    "# Analyze all generated files\n",
    "for midi_file in Path(\"./output\").glob(\"**/*.mid\"):\n",
    "    analyze_midi(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Context Length\n",
    "\n",
    "### Training vs Inference:\n",
    "- **Training**: Model was trained with `context_length=2048`\n",
    "- **Inference**: You can use `context_length=4096` or higher\n",
    "  - The model can handle longer sequences\n",
    "  - But memory usage grows quadratically (NÂ² for mLSTM)\n",
    "\n",
    "### Memory Usage:\n",
    "- `context_length=2048` â†’ ~10GB VRAM\n",
    "- `context_length=4096` â†’ ~40GB VRAM  \n",
    "- `context_length=8192` â†’ ~160GB VRAM (likely OOM)\n",
    "\n",
    "### Solution for Long Generation:\n",
    "Use **sliding window** (implemented in `generate_long()`):\n",
    "- Keep only last N tokens as context\n",
    "- Generate new chunk\n",
    "- Slide window forward\n",
    "- Repeat\n",
    "\n",
    "This keeps memory constant while generating arbitrarily long sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Prompts\n",
    "\n",
    "REMIGEN format: `s-X o-Y t-Z i-A p-B d-C v-D ...`\n",
    "\n",
    "- `s-X`: Signature (time signature)\n",
    "- `o-Y`: Offset (timing)\n",
    "- `t-Z`: Tempo\n",
    "- `i-A`: Instrument\n",
    "- `p-B`: Pitch\n",
    "- `d-C`: Duration\n",
    "- `v-D`: Velocity\n",
    "- `b-1`: Bar marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different starting prompts\n",
    "prompts = [\n",
    "    \"s-9 o-0 t-35\",  # Slow tempo\n",
    "    \"s-9 o-0 t-120\", # Fast tempo\n",
    "    \"s-9 o-0 t-60 i-0\",  # With piano\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    result = generator.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=0.8,\n",
    "        max_tokens=1500,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    midi_path = f\"./output/custom_prompt_{i}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], midi_path)\n",
    "    print(f\"Saved: {midi_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Museformer\n",
    "\n",
    "For your research comparison, you can now:\n",
    "\n",
    "1. Generate same number of pieces from both models\n",
    "2. Use same prompts/seeds\n",
    "3. Compare:\n",
    "   - Musicality\n",
    "   - Coherence over long sequences\n",
    "   - Diversity\n",
    "   - Computational requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate evaluation dataset\n",
    "eval_output = Path(\"./evaluation/xlstm_samples\")\n",
    "eval_output.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for i in range(20):  # Generate 20 samples\n",
    "    result = generator.generate(\n",
    "        prompt=\"s-9 o-0 t-35\",\n",
    "        temperature=0.8,\n",
    "        max_tokens=2048,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    midi_path = eval_output / f\"xlstm_{i:03d}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], str(midi_path))\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Generated {i+1}/20 samples\")\n",
    "\n",
    "print(f\"\\nâœ“ Evaluation dataset ready: {eval_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
