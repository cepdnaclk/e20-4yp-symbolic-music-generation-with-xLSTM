{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xLSTM Music Generation - Clean Pipeline\n",
    "\n",
    "This notebook provides a clean, modular approach to generating music with your trained xLSTM model.\n",
    "\n",
    "## Key Fixes from Your Original Code:\n",
    "\n",
    "1. **Memory Issue Fixed**: The problem was `max_length` growing with each iteration\n",
    "   - **Wrong**: `max_length = len(output.split()) + chunk_size` (creates quadratic memory growth)\n",
    "   - **Right**: Use fixed `max_length` OR sliding window context\n",
    "\n",
    "2. **Context Length**: You can use larger context during inference than training\n",
    "   - Trained with 2048 â†’ Can infer with 4096 or more\n",
    "   - But memory grows with contextÂ² in mLSTM\n",
    "\n",
    "3. **Modular Design**: Clean separation of generation and conversion logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello0\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna\")\n",
    "\n",
    "from xlstm_music_generation import MusicGenerator, MIDIConverter, generate_music\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0;8.6;8.9'\n",
    "os.environ['MAX_JOBS'] = '4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/xlstm_lmd_512d_2048ctx_12b/run_20260126-0516\n",
      "\u001b[32m\u001b[1m   â–„â–ˆ    â–ˆâ–„       â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–„â–ˆ        â–„â–ˆ  â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„     â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–„  â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„   â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„      â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„ â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–€  â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–„â–„  â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„     â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ  â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–ˆâ–ˆâ–€   â–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆâ–€ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1mâ–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–€â–ˆâ–ˆâ–ˆâ–€  â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€     â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆâ–Œ â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–ˆâ–ˆâ–„  â–€â–€â–ˆâ–ˆâ–ˆâ–€â–€â–€â–€â–€   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–„  â–ˆâ–ˆâ–ˆ       â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–„ â–€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[1m  â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–Œ    â–„ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ \n",
      "\u001b[32m\u001b[22m  â–ˆâ–ˆâ–ˆ    â–ˆâ–€      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–ˆâ–ˆ â–ˆâ–€   â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–€    â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–€   â–€â–ˆ   â–ˆâ–€   â–€â–ˆ   â–ˆâ–€    â–ˆâ–ˆâ–ˆ    â–ˆâ–€  \n",
      "\u001b[32m\u001b[1m                            â–€                             â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ                                             \n",
      "\u001b[32m\u001b[22m\n",
      "\u001b[32m\u001b[1mBy Dr. Tristan Behrens\n",
      "\u001b[0m\n",
      "{\n",
      "    \"embedding_dim\": 512,\n",
      "    \"num_blocks\": 12,\n",
      "    \"context_length\": 16384,\n",
      "    \"slstm_at\": [\n",
      "        3,\n",
      "        6,\n",
      "        9\n",
      "    ],\n",
      "    \"mlstm_block\": {\n",
      "        \"mlstm\": {\n",
      "            \"conv1d_kernel_size\": 4,\n",
      "            \"qkv_proj_blocksize\": 4,\n",
      "            \"num_heads\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_block\": {\n",
      "        \"slstm\": {\n",
      "            \"backend\": \"cuda\",\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4,\n",
      "            \"bias_init\": \"powerlaw_blockdependent\"\n",
      "        },\n",
      "        \"feedforward\": {\n",
      "            \"proj_factor\": 1.3,\n",
      "            \"act_fn\": \"gelu\"\n",
      "        }\n",
      "    },\n",
      "    \"vocab_size\": 675\n",
      "}\n",
      "Creating xLSTMLMModel...\n",
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/e20037/.cache/torch_extensions/py311_cu124/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
      "Building extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "Using envvar MAX_JOBS (4) as the number of workers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skipping build step...\n",
      "Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skipping build step...\n",
      "Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2165: FutureWarning: Calling PreTrainedTokenizerFast.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded (context: 16384 tokens)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MODEL_PATH = \"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/lmd_remigen_xlstm/run_20260115-1028\"\n",
    "\n",
    "# Context-2048, embedding-512\n",
    "MODEL_PATH = \"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/xlstm_lmd_512d_2048ctx_12b/run_20260126-0516\"\n",
    "\n",
    "# For short sequences (< 2048 tokens)\n",
    "generator = MusicGenerator(\n",
    "    model_path=MODEL_PATH,\n",
    "    context_length=16_384,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "converter = MIDIConverter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BATCH GENERATION\n",
      "======================================================================\n",
      "Temperatures: [0.6, 0.7, 0.8, 0.9]\n",
      "Target bars: [16, 32, 48, 64]\n",
      "Pieces per combination: 5\n",
      "Total pieces: 80\n",
      "Output directory: ./generated_batch_20260208_041715\n",
      "======================================================================\n",
      "\n",
      "[1/80] Generating temp_0.6_bars_16_001.mid...\n",
      "   âœ“ Success - 30 bars, 780 tokens\n",
      "   Time: 20.8s, Cleaning: No\n",
      "\n",
      "[2/80] Generating temp_0.6_bars_16_002.mid...\n",
      "   âœ“ Success - 17 bars, 1690 tokens\n",
      "   Time: 71.8s, Cleaning: No\n",
      "\n",
      "[3/80] Generating temp_0.6_bars_16_003.mid...\n",
      "   âœ“ Success - 20 bars, 1480 tokens\n",
      "   Time: 52.0s, Cleaning: No\n",
      "\n",
      "[4/80] Generating temp_0.6_bars_16_004.mid...\n",
      "   âœ“ Success - 19 bars, 1138 tokens\n",
      "   Time: 34.1s, Cleaning: No\n",
      "\n",
      "[5/80] Generating temp_0.6_bars_16_005.mid...\n",
      "   âœ“ Success - 18 bars, 1448 tokens\n",
      "   Time: 51.2s, Cleaning: No\n",
      "\n",
      "[6/80] Generating temp_0.6_bars_32_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 32 bars, 4340 tokens\n",
      "   Time: 259.5s, Cleaning: Yes\n",
      "\n",
      "[7/80] Generating temp_0.6_bars_32_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 9 bars, 2361 tokens\n",
      "   Time: 162.4s, Cleaning: Yes\n",
      "\n",
      "[8/80] Generating temp_0.6_bars_32_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 25 bars, 6485 tokens\n",
      "   Time: 511.6s, Cleaning: Yes\n",
      "\n",
      "[9/80] Generating temp_0.6_bars_32_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 32 bars, 4112 tokens\n",
      "   Time: 255.7s, Cleaning: Yes\n",
      "\n",
      "[10/80] Generating temp_0.6_bars_32_005.mid...\n",
      "   âœ“ Success - 36 bars, 2301 tokens\n",
      "   Time: 94.0s, Cleaning: No\n",
      "\n",
      "[11/80] Generating temp_0.6_bars_48_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 48 bars, 4974 tokens\n",
      "   Time: 313.1s, Cleaning: Yes\n",
      "\n",
      "[12/80] Generating temp_0.6_bars_48_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 49 bars, 4788 tokens\n",
      "   Time: 261.6s, Cleaning: Yes\n",
      "\n",
      "[13/80] Generating temp_0.6_bars_48_003.mid...\n",
      "   âœ“ Success - 12 bars, 1665 tokens\n",
      "   Time: 107.3s, Cleaning: No\n",
      "\n",
      "[14/80] Generating temp_0.6_bars_48_004.mid...\n",
      "   âœ“ Success - 48 bars, 2400 tokens\n",
      "   Time: 98.4s, Cleaning: No\n",
      "\n",
      "[15/80] Generating temp_0.6_bars_48_005.mid...\n",
      "   âœ“ Success - 50 bars, 3016 tokens\n",
      "   Time: 143.4s, Cleaning: No\n",
      "\n",
      "[16/80] Generating temp_0.6_bars_64_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 66 bars, 7425 tokens\n",
      "   Time: 514.1s, Cleaning: Yes\n",
      "\n",
      "[17/80] Generating temp_0.6_bars_64_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 64 bars, 7714 tokens\n",
      "   Time: 578.5s, Cleaning: Yes\n",
      "\n",
      "[18/80] Generating temp_0.6_bars_64_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 71 bars, 2628 tokens\n",
      "   Time: 131.4s, Cleaning: Yes\n",
      "\n",
      "[19/80] Generating temp_0.6_bars_64_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 66 bars, 6954 tokens\n",
      "   Time: 486.2s, Cleaning: Yes\n",
      "\n",
      "[20/80] Generating temp_0.6_bars_64_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 14 bars, 2447 tokens\n",
      "   Time: 169.9s, Cleaning: Yes\n",
      "\n",
      "[21/80] Generating temp_0.7_bars_16_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 16 bars, 2073 tokens\n",
      "   Time: 121.4s, Cleaning: Yes\n",
      "\n",
      "[22/80] Generating temp_0.7_bars_16_002.mid...\n",
      "   âœ“ Success - 11 bars, 1628 tokens\n",
      "   Time: 104.1s, Cleaning: No\n",
      "\n",
      "[23/80] Generating temp_0.7_bars_16_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 17 bars, 2098 tokens\n",
      "   Time: 121.0s, Cleaning: Yes\n",
      "\n",
      "[24/80] Generating temp_0.7_bars_16_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 17 bars, 1958 tokens\n",
      "   Time: 101.3s, Cleaning: Yes\n",
      "\n",
      "[25/80] Generating temp_0.7_bars_16_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 17 bars, 1998 tokens\n",
      "   Time: 124.8s, Cleaning: Yes\n",
      "\n",
      "[26/80] Generating temp_0.7_bars_32_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 33 bars, 2903 tokens\n",
      "   Time: 178.7s, Cleaning: Yes\n",
      "\n",
      "[27/80] Generating temp_0.7_bars_32_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 33 bars, 3796 tokens\n",
      "   Time: 258.2s, Cleaning: Yes\n",
      "\n",
      "[28/80] Generating temp_0.7_bars_32_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 19 bars, 2208 tokens\n",
      "   Time: 148.1s, Cleaning: Yes\n",
      "\n",
      "[29/80] Generating temp_0.7_bars_32_004.mid...\n",
      "   âœ“ Success - 34 bars, 1838 tokens\n",
      "   Time: 85.1s, Cleaning: No\n",
      "\n",
      "[30/80] Generating temp_0.7_bars_32_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 33 bars, 4501 tokens\n",
      "   Time: 353.0s, Cleaning: Yes\n",
      "\n",
      "[31/80] Generating temp_0.7_bars_48_001.mid...\n",
      "   âœ“ Success - 48 bars, 1539 tokens\n",
      "   Time: 53.2s, Cleaning: No\n",
      "\n",
      "[32/80] Generating temp_0.7_bars_48_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 54 bars, 3011 tokens\n",
      "   Time: 146.1s, Cleaning: Yes\n",
      "\n",
      "[33/80] Generating temp_0.7_bars_48_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 50 bars, 5401 tokens\n",
      "   Time: 344.5s, Cleaning: Yes\n",
      "\n",
      "[34/80] Generating temp_0.7_bars_48_004.mid...\n",
      "   âœ“ Success - 7 bars, 1818 tokens\n",
      "   Time: 112.1s, Cleaning: No\n",
      "\n",
      "[35/80] Generating temp_0.7_bars_48_005.mid...\n",
      "   âœ“ Success - 48 bars, 1248 tokens\n",
      "   Time: 46.0s, Cleaning: No\n",
      "\n",
      "[36/80] Generating temp_0.7_bars_64_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 10 bars, 2084 tokens\n",
      "   Time: 179.7s, Cleaning: Yes\n",
      "\n",
      "[37/80] Generating temp_0.7_bars_64_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 31 bars, 2154 tokens\n",
      "   Time: 133.7s, Cleaning: Yes\n",
      "\n",
      "[38/80] Generating temp_0.7_bars_64_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 64 bars, 7946 tokens\n",
      "   Time: 574.7s, Cleaning: Yes\n",
      "\n",
      "[39/80] Generating temp_0.7_bars_64_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 48 bars, 9185 tokens\n",
      "   Time: 707.0s, Cleaning: Yes\n",
      "\n",
      "[40/80] Generating temp_0.7_bars_64_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 9 bars, 2214 tokens\n",
      "   Time: 165.8s, Cleaning: Yes\n",
      "\n",
      "[41/80] Generating temp_0.8_bars_16_001.mid...\n",
      "   âœ“ Success - 16 bars, 1822 tokens\n",
      "   Time: 97.2s, Cleaning: No\n",
      "\n",
      "[42/80] Generating temp_0.8_bars_16_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 8 bars, 1959 tokens\n",
      "   Time: 112.5s, Cleaning: Yes\n",
      "\n",
      "[43/80] Generating temp_0.8_bars_16_003.mid...\n",
      "   âœ“ Success - 17 bars, 1047 tokens\n",
      "   Time: 34.5s, Cleaning: No\n",
      "\n",
      "[44/80] Generating temp_0.8_bars_16_004.mid...\n",
      "   âœ“ Success - 17 bars, 1086 tokens\n",
      "   Time: 33.7s, Cleaning: No\n",
      "\n",
      "[45/80] Generating temp_0.8_bars_16_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 17 bars, 2696 tokens\n",
      "   Time: 157.8s, Cleaning: Yes\n",
      "\n",
      "[46/80] Generating temp_0.8_bars_32_001.mid...\n",
      "   âœ“ Success - 12 bars, 1622 tokens\n",
      "   Time: 93.9s, Cleaning: No\n",
      "\n",
      "[47/80] Generating temp_0.8_bars_32_002.mid...\n",
      "   âœ“ Success - 33 bars, 1779 tokens\n",
      "   Time: 86.3s, Cleaning: No\n",
      "\n",
      "[48/80] Generating temp_0.8_bars_32_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 11 bars, 2004 tokens\n",
      "   Time: 143.1s, Cleaning: Yes\n",
      "\n",
      "[49/80] Generating temp_0.8_bars_32_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 26 bars, 4106 tokens\n",
      "   Time: 302.9s, Cleaning: Yes\n",
      "\n",
      "[50/80] Generating temp_0.8_bars_32_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 33 bars, 1890 tokens\n",
      "   Time: 83.6s, Cleaning: Yes\n",
      "\n",
      "[51/80] Generating temp_0.8_bars_48_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 47 bars, 7896 tokens\n",
      "   Time: 664.1s, Cleaning: Yes\n",
      "\n",
      "[52/80] Generating temp_0.8_bars_48_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 15 bars, 3229 tokens\n",
      "   Time: 275.7s, Cleaning: Yes\n",
      "\n",
      "[53/80] Generating temp_0.8_bars_48_003.mid...\n",
      "   âœ“ Success - 7 bars, 1528 tokens\n",
      "   Time: 104.2s, Cleaning: No\n",
      "\n",
      "[54/80] Generating temp_0.8_bars_48_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 49 bars, 5417 tokens\n",
      "   Time: 396.5s, Cleaning: Yes\n",
      "\n",
      "[55/80] Generating temp_0.8_bars_48_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 48 bars, 7936 tokens\n",
      "   Time: 628.9s, Cleaning: Yes\n",
      "\n",
      "[56/80] Generating temp_0.8_bars_64_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 51 bars, 8529 tokens\n",
      "   Time: 681.4s, Cleaning: Yes\n",
      "\n",
      "[57/80] Generating temp_0.8_bars_64_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 65 bars, 7156 tokens\n",
      "   Time: 535.3s, Cleaning: Yes\n",
      "\n",
      "[58/80] Generating temp_0.8_bars_64_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 65 bars, 8539 tokens\n",
      "   Time: 659.5s, Cleaning: Yes\n",
      "\n",
      "[59/80] Generating temp_0.8_bars_64_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 36 bars, 4347 tokens\n",
      "   Time: 468.4s, Cleaning: Yes\n",
      "\n",
      "[60/80] Generating temp_0.8_bars_64_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 64 bars, 8205 tokens\n",
      "   Time: 1017.2s, Cleaning: Yes\n",
      "\n",
      "[61/80] Generating temp_0.9_bars_16_001.mid...\n",
      "   âœ“ Success - 16 bars, 770 tokens\n",
      "   Time: 35.6s, Cleaning: No\n",
      "\n",
      "[62/80] Generating temp_0.9_bars_16_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 18 bars, 2562 tokens\n",
      "   Time: 271.9s, Cleaning: Yes\n",
      "\n",
      "[63/80] Generating temp_0.9_bars_16_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 16 bars, 2705 tokens\n",
      "   Time: 387.3s, Cleaning: Yes\n",
      "\n",
      "[64/80] Generating temp_0.9_bars_16_004.mid...\n",
      "   âœ“ Success - 2 bars, 726 tokens\n",
      "   Time: 63.2s, Cleaning: No\n",
      "\n",
      "[65/80] Generating temp_0.9_bars_16_005.mid...\n",
      "   âœ“ Success - 16 bars, 1576 tokens\n",
      "   Time: 137.0s, Cleaning: No\n",
      "\n",
      "[66/80] Generating temp_0.9_bars_32_001.mid...\n",
      "   âœ“ Success - 3 bars, 714 tokens\n",
      "   Time: 79.6s, Cleaning: No\n",
      "\n",
      "[67/80] Generating temp_0.9_bars_32_002.mid...\n",
      "   âœ“ Success - 6 bars, 1609 tokens\n",
      "   Time: 197.9s, Cleaning: No\n",
      "\n",
      "[68/80] Generating temp_0.9_bars_32_003.mid...\n",
      "   âœ“ Success - 32 bars, 3341 tokens\n",
      "   Time: 353.7s, Cleaning: No\n",
      "\n",
      "[69/80] Generating temp_0.9_bars_32_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 7 bars, 2141 tokens\n",
      "   Time: 225.1s, Cleaning: Yes\n",
      "\n",
      "[70/80] Generating temp_0.9_bars_32_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 13 bars, 2054 tokens\n",
      "   Time: 258.4s, Cleaning: Yes\n",
      "\n",
      "[71/80] Generating temp_0.9_bars_48_001.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 45 bars, 5342 tokens\n",
      "   Time: 769.1s, Cleaning: Yes\n",
      "\n",
      "[72/80] Generating temp_0.9_bars_48_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 48 bars, 8089 tokens\n",
      "   Time: 1133.6s, Cleaning: Yes\n",
      "\n",
      "[73/80] Generating temp_0.9_bars_48_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 50 bars, 5423 tokens\n",
      "   Time: 680.2s, Cleaning: Yes\n",
      "\n",
      "[74/80] Generating temp_0.9_bars_48_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 49 bars, 5204 tokens\n",
      "   Time: 633.4s, Cleaning: Yes\n",
      "\n",
      "[75/80] Generating temp_0.9_bars_48_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 44 bars, 9198 tokens\n",
      "   Time: 1365.3s, Cleaning: Yes\n",
      "\n",
      "[76/80] Generating temp_0.9_bars_64_001.mid...\n",
      "   âœ“ Success - 26 bars, 1748 tokens\n",
      "   Time: 159.2s, Cleaning: No\n",
      "\n",
      "[77/80] Generating temp_0.9_bars_64_002.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 64 bars, 10067 tokens\n",
      "   Time: 1268.8s, Cleaning: Yes\n",
      "\n",
      "[78/80] Generating temp_0.9_bars_64_003.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 46 bars, 6036 tokens\n",
      "   Time: 833.9s, Cleaning: Yes\n",
      "\n",
      "[79/80] Generating temp_0.9_bars_64_004.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 64 bars, 7903 tokens\n",
      "   Time: 987.6s, Cleaning: Yes\n",
      "\n",
      "[80/80] Generating temp_0.9_bars_64_005.mid...\n",
      "âœ— Decoding error: AssertionError: \n",
      "   First attempt failed, trying with cleaning...\n",
      "   âœ“ Success - 24 bars, 4650 tokens\n",
      "   Time: 364.2s, Cleaning: Yes\n",
      "\n",
      "======================================================================\n",
      "BATCH GENERATION COMPLETE\n",
      "======================================================================\n",
      "Output directory: ./generated_batch_20260208_041715\n",
      "Analysis report: ./generated_batch_20260208_041715/analysis_report.txt\n",
      "Success rate: 80/80\n"
     ]
    }
   ],
   "source": [
    "batch_results = generator.generate_batch(\n",
    "    temperatures=[0.6, 0.7, 0.8, 0.9],\n",
    "    target_bars_list=[16, 32, 48, 64],\n",
    "    pieces_per_combination=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"s-9 o-42 t-36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Long generation (bar-aware chunking)...\n",
      "   Target: 32 bars\n",
      "   Strategy: Generate 2-3 bars per iteration, cut at b-1\n",
      "\n",
      "ðŸ“ Iteration 1/50\n",
      "   Context: 3 tokens (0 bars)\n",
      "   Generated: 400 tokens\n",
      "   Kept (complete bars): 307 tokens (4 bars)\n",
      "   Total: 310 tokens (4 bars)\n",
      "\n",
      "ðŸ“ Iteration 2/50\n",
      "   Context: 310 tokens (4 bars)\n",
      "   Generated: 400 tokens\n",
      "   Kept (complete bars): 400 tokens (4 bars)\n",
      "   Total: 710 tokens (8 bars)\n",
      "\n",
      "ðŸ“ Iteration 3/50\n",
      "   Context: 710 tokens (8 bars)\n",
      "   Generated: 400 tokens\n",
      "   Kept (complete bars): 400 tokens (4 bars)\n",
      "   Total: 1110 tokens (12 bars)\n",
      "\n",
      "ðŸ“ Iteration 4/50\n",
      "   Context: 1110 tokens (12 bars)\n",
      "   Generated: 400 tokens\n",
      "   Kept (complete bars): 400 tokens (4 bars)\n",
      "   Total: 1510 tokens (16 bars)\n",
      "\n",
      "ðŸ“ Iteration 5/50\n",
      "   Context: 1500 tokens (16 bars)\n",
      "   Generated: 398 tokens\n",
      "   Kept (complete bars): 398 tokens (4 bars)\n",
      "   Total: 1908 tokens (20 bars)\n",
      "\n",
      "ðŸ“ Iteration 6/50\n",
      "   Context: 1500 tokens (16 bars)\n",
      "   Generated: 399 tokens\n",
      "   Kept (complete bars): 399 tokens (4 bars)\n",
      "   Total: 2307 tokens (24 bars)\n",
      "\n",
      "ðŸ“ Iteration 7/50\n",
      "   Context: 1500 tokens (16 bars)\n",
      "   Generated: 399 tokens\n",
      "   Kept (complete bars): 399 tokens (4 bars)\n",
      "   Total: 2706 tokens (28 bars)\n",
      "\n",
      "ðŸ“ Iteration 8/50\n",
      "   Context: 1500 tokens (16 bars)\n",
      "   Generated: 394 tokens\n",
      "   Kept (complete bars): 300 tokens (3 bars)\n",
      "   Total: 3006 tokens (31 bars)\n",
      "\n",
      "ðŸ“ Iteration 9/50\n",
      "   Context: 1500 tokens (16 bars)\n",
      "   Generated: 400 tokens\n",
      "   Kept (complete bars): 286 tokens (2 bars)\n",
      "   Total: 3292 tokens (33 bars)\n",
      "\n",
      "âœ“ Reached target: 33 bars\n",
      "\n",
      "âœ“ Generation complete!\n",
      "   Final: 3292 tokens, 33 bars\n"
     ]
    }
   ],
   "source": [
    "result = generator.generate_long(\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    target_bars=32,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOKEN ANALYSIS REPORT\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERALL STATISTICS:\n",
      "   Total tokens: 3292\n",
      "   Total bars: 33\n",
      "   Total notes: 698\n",
      "   Unique instruments: 3\n",
      "\n",
      "ðŸŽµ BAR STATISTICS:\n",
      "   Average bar length: 98.8 tokens\n",
      "   Min bar length: 13 tokens\n",
      "   Max bar length: 169 tokens\n",
      "\n",
      "ðŸ”¤ TOKEN TYPES:\n",
      "   b-: 33\n",
      "   d-: 698\n",
      "   i-: 553\n",
      "   o-: 290\n",
      "   p-: 698\n",
      "   s-: 33\n",
      "   t-: 290\n",
      "   v-: 697\n",
      "\n",
      "ðŸŽ¹ INSTRUMENTS:\n",
      "   i-128\n",
      "   i-29\n",
      "   i-30\n",
      "\n",
      "âœ… SEQUENCE HEALTH:\n",
      "   Ends with b-1: âœ“\n",
      "   Grammar errors: 4\n",
      "\n",
      "âš ï¸  GRAMMAR ERRORS (showing first 5):\n",
      "   - Incomplete triplet at token 1696: p-53 d-4 (missing velocity)\n",
      "   - Incomplete triplet at token 1899: p-166 d-2 (missing velocity)\n",
      "   - Orphan token at 2248: d-4\n",
      "   - Incomplete triplet at token 2628: p-164 (missing duration)\n",
      "\n",
      "ðŸ” SEQUENCE EDGES:\n",
      "   First 10 tokens: s-9 o-42 t-36 i-128 p-166 d-2 v-28 o-45 t-36 i-128\n",
      "   Last 10 tokens: d-2 v-31 p-64 d-2 v-31 i-128 p-166 d-2 v-28 b-1\n",
      "============================================================\n",
      "Found 4 grammar errors!\n"
     ]
    }
   ],
   "source": [
    "# Analyze\n",
    "analysis = generator.analyze_tokens(result['tokens'], verbose=True)\n",
    "\n",
    "# Check for issues\n",
    "if analysis['has_errors']:\n",
    "    print(f\"Found {len(analysis['grammar_errors'])} grammar errors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ— Decoding error: AssertionError: \n",
      "Success: False\n"
     ]
    }
   ],
   "source": [
    "# Try decoding WITHOUT cleaning\n",
    "success = converter.tokens_to_midi(result['tokens'], \"./output/long_clean.mid\", clean=False)\n",
    "print(f\"Success: {success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "# Try decoding WITH cleaning\n",
    "success = converter.tokens_to_midi(result['tokens'], \"./output/long_clean.mid\", clean=True)\n",
    "print(f\"Success: {success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug the last tokens\n",
    "tokens_list = result['tokens'].split()\n",
    "print(f\"Total: {len(tokens_list)}\")\n",
    "print(f\"Last 30 tokens: {tokens_list[-30:]}\")\n",
    "print(f\"Ends with b-1? {tokens_list[-1] == 'b-1'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽµ Generating...\n",
      "   Prompt: s-9 o-0 t-35...\n",
      "   Max tokens: 2000\n",
      "   Temperature: 0.8\n",
      "âœ“ Generated 2000 tokens (10 bars)\n"
     ]
    }
   ],
   "source": [
    "# Try single-shot generation with larger max_length\n",
    "result = generator.generate(\n",
    "    prompt=\"s-9 o-0 t-35\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=2000,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: ./output/ctx4096-full-trained/sample_1_ct4096-len1990.mid\n",
      "Generated 2000 tokens, 10 bars\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "output_path = \"./output/ctx2048-full-trained/sample_1_ct4096-len1990.mid\"\n",
    "success = converter.tokens_to_midi(result['tokens'], output_path, clean=False)\n",
    "\n",
    "if success:\n",
    "    print(f\"âœ“ Saved: {output_path}\")\n",
    "    print(f\"Generated {result['num_tokens']} tokens, {result['bars']} bars\")\n",
    "else:\n",
    "    print(\"Decoding failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: see what token is causing the error\n",
    "tokens = result['tokens'].split()\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(f\"Last 30 tokens: {tokens[-30:]}\")\n",
    "\n",
    "# Find incomplete triplets\n",
    "for i, token in enumerate(tokens[-30:], start=len(tokens)-30):\n",
    "    if token.startswith('p-'):\n",
    "        if i+1 >= len(tokens) or not tokens[i+1].startswith('d-'):\n",
    "            print(f\"Incomplete at {i}: {token} (no duration)\")\n",
    "        elif i+2 >= len(tokens) or not tokens[i+2].startswith('v-'):\n",
    "            print(f\"Incomplete at {i}: {token} {tokens[i+1]} (no velocity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Generate Short Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple generation\n",
    "result = generator.generate(\n",
    "    prompt=\"s-9 o-0 t-38\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=3000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {result['num_tokens']} tokens, {result['bars']} bars\")\n",
    "\n",
    "# Convert to MIDI\n",
    "output_path = \"./output/test_song.mid\"\n",
    "converter.tokens_to_midi(result['tokens'], output_path)\n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Generate Long Piece (Chunked)\n",
    "\n",
    "This uses **sliding window** approach to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For long generation, use larger context\n",
    "long_generator = MusicGenerator(\n",
    "    model_path=MODEL_PATH,\n",
    "    context_length=4096,  # Larger than training\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "result = long_generator.generate_long(\n",
    "    prompt=\"s-9 o-30 t-33 i-128 p-176 d-6 v-23 o-36 t-33 i-128 p-173 d-6 v-23 o-42 t-33 i-128 p-171 d-6 v-23 b-1 s-9 o-0 t-33 i-4 p-81 d-25\",\n",
    "    temperature=0.8,\n",
    "    target_bars=64,       # Generate 64 bars\n",
    "    chunk_tokens=1024,    # 1024 new tokens per iteration\n",
    "    max_iterations=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save\n",
    "output_path = \"./output/long_song.mid\"\n",
    "converter.tokens_to_midi(result['tokens'], output_path)\n",
    "print(f\"\\nSaved {result['bars']} bars to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add detailed error reporting\n",
    "cleaned = converter.clean_tokens(result['tokens'])\n",
    "print(f\"Cleaned: {len(cleaned.split())} tokens\")\n",
    "print(f\"Last 20 cleaned: {cleaned.split()[-20:]}\")\n",
    "\n",
    "try:\n",
    "    midi_obj = converter.decoder.decode_from_token_str_list(cleaned.split())\n",
    "    print(\"âœ“ Decoding successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Batch Generation with Different Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [0.5, 0.8, 1.0, 1.2]\n",
    "output_dir = Path(\"./output/temp_comparison\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = generator.generate(\n",
    "        prompt=\"s-9 o-0 t-35\",\n",
    "        temperature=temp,\n",
    "        max_tokens=2000,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    midi_path = output_dir / f\"temp_{temp:.1f}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], str(midi_path))\n",
    "    print(f\"âœ“ Saved: {midi_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Simple API (One Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 songs with one function call\n",
    "outputs = generate_music(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_songs=5,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    output_dir=\"./output/batch\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(outputs)} songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Long Mode with Simple API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate long pieces\n",
    "outputs = generate_music(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_songs=2,\n",
    "    temperature=0.8,\n",
    "    output_dir=\"./output/long_batch\",\n",
    "    long_mode=True,\n",
    "    target_bars=64\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(outputs)} long songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Generated MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "def analyze_midi(midi_path):\n",
    "    midi = pretty_midi.PrettyMIDI(str(midi_path))\n",
    "    \n",
    "    print(f\"File: {midi_path.name}\")\n",
    "    print(f\"Duration: {midi.get_end_time():.2f}s\")\n",
    "    print(f\"Instruments: {len(midi.instruments)}\")\n",
    "    print(f\"Total notes: {sum(len(inst.notes) for inst in midi.instruments)}\")\n",
    "    \n",
    "    for inst in midi.instruments:\n",
    "        inst_type = \"Drums\" if inst.is_drum else f\"Program {inst.program}\"\n",
    "        print(f\"  - {inst.name}: {len(inst.notes)} notes ({inst_type})\")\n",
    "    print()\n",
    "\n",
    "# Analyze all generated files\n",
    "for midi_file in Path(\"./output\").glob(\"**/*.mid\"):\n",
    "    analyze_midi(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Context Length\n",
    "\n",
    "### Training vs Inference:\n",
    "- **Training**: Model was trained with `context_length=2048`\n",
    "- **Inference**: You can use `context_length=4096` or higher\n",
    "  - The model can handle longer sequences\n",
    "  - But memory usage grows quadratically (NÂ² for mLSTM)\n",
    "\n",
    "### Memory Usage:\n",
    "- `context_length=2048` â†’ ~10GB VRAM\n",
    "- `context_length=4096` â†’ ~40GB VRAM  \n",
    "- `context_length=8192` â†’ ~160GB VRAM (likely OOM)\n",
    "\n",
    "### Solution for Long Generation:\n",
    "Use **sliding window** (implemented in `generate_long()`):\n",
    "- Keep only last N tokens as context\n",
    "- Generate new chunk\n",
    "- Slide window forward\n",
    "- Repeat\n",
    "\n",
    "This keeps memory constant while generating arbitrarily long sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Prompts\n",
    "\n",
    "REMIGEN format: `s-X o-Y t-Z i-A p-B d-C v-D ...`\n",
    "\n",
    "- `s-X`: Signature (time signature)\n",
    "- `o-Y`: Offset (timing)\n",
    "- `t-Z`: Tempo\n",
    "- `i-A`: Instrument\n",
    "- `p-B`: Pitch\n",
    "- `d-C`: Duration\n",
    "- `v-D`: Velocity\n",
    "- `b-1`: Bar marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different starting prompts\n",
    "prompts = [\n",
    "    \"s-9 o-0 t-35\",  # Slow tempo\n",
    "    \"s-9 o-0 t-120\", # Fast tempo\n",
    "    \"s-9 o-0 t-60 i-0\",  # With piano\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    result = generator.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=0.8,\n",
    "        max_tokens=1500,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    midi_path = f\"./output/custom_prompt_{i}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], midi_path)\n",
    "    print(f\"Saved: {midi_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Museformer\n",
    "\n",
    "For your research comparison, you can now:\n",
    "\n",
    "1. Generate same number of pieces from both models\n",
    "2. Use same prompts/seeds\n",
    "3. Compare:\n",
    "   - Musicality\n",
    "   - Coherence over long sequences\n",
    "   - Diversity\n",
    "   - Computational requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate evaluation dataset\n",
    "eval_output = Path(\"./evaluation/xlstm_samples\")\n",
    "eval_output.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for i in range(20):  # Generate 20 samples\n",
    "    result = generator.generate(\n",
    "        prompt=\"s-9 o-0 t-35\",\n",
    "        temperature=0.8,\n",
    "        max_tokens=2048,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    midi_path = eval_output / f\"xlstm_{i:03d}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], str(midi_path))\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Generated {i+1}/20 samples\")\n",
    "\n",
    "print(f\"\\nâœ“ Evaluation dataset ready: {eval_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
