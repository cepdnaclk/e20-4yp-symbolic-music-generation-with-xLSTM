{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xLSTM Music Generation - Clean Pipeline\n",
    "\n",
    "This notebook provides a clean, modular approach to generating music with your trained xLSTM model.\n",
    "\n",
    "## Key Fixes from Your Original Code:\n",
    "\n",
    "1. **Memory Issue Fixed**: The problem was `max_length` growing with each iteration\n",
    "   - **Wrong**: `max_length = len(output.split()) + chunk_size` (creates quadratic memory growth)\n",
    "   - **Right**: Use fixed `max_length` OR sliding window context\n",
    "\n",
    "2. **Context Length**: You can use larger context during inference than training\n",
    "   - Trained with 2048 ‚Üí Can infer with 4096 or more\n",
    "   - But memory grows with context¬≤ in mLSTM\n",
    "\n",
    "3. **Modular Design**: Clean separation of generation and conversion logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello0\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna\")\n",
    "\n",
    "from xlstm_music_generation import MusicGenerator, MIDIConverter, generate_music\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = '8.0;8.6;8.9'\n",
    "os.environ['MAX_JOBS'] = '4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/lmd_remigen_xlstm/run_20260115-1028\n",
      "\u001b[32m\u001b[1m   ‚ñÑ‚ñà    ‚ñà‚ñÑ       ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñÑ‚ñà        ‚ñÑ‚ñà  ‚ñÄ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ     ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñÑ  ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ   ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ      ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñÑ ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñÑ   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[1m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñÄ  ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà‚ñå   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ  ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ     ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà‚ñå  ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÄ   ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÄ ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[1m‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ  ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ     ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà‚ñå ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñÑ  ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñÄ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñÑ  ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñÑ ‚ñÄ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[1m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñå    ‚ñÑ ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m  ‚ñà‚ñà‚ñà    ‚ñà‚ñÄ      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà ‚ñà‚ñÄ   ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÄ    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÄ   ‚ñÄ‚ñà   ‚ñà‚ñÄ   ‚ñÄ‚ñà   ‚ñà‚ñÄ    ‚ñà‚ñà‚ñà    ‚ñà‚ñÄ  \n",
      "\u001b[32m\u001b[1m                            ‚ñÄ                             ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà                                             \n",
      "\u001b[32m\u001b[22m\n",
      "\u001b[32m\u001b[1mBy Dr. Tristan Behrens\n",
      "\u001b[0m\n",
      "{\n",
      "    \"num_blocks\": 12,\n",
      "    \"embedding_dim\": 256,\n",
      "    \"mlstm_block\": {\n",
      "        \"mlstm\": {\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_block\": {\n",
      "        \"slstm\": {\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_at\": [\n",
      "        3,\n",
      "        6,\n",
      "        9\n",
      "    ],\n",
      "    \"context_length\": 8192,\n",
      "    \"vocab_size\": 675\n",
      "}\n",
      "Creating xLSTMLMModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded (context: 8192 tokens)\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/lmd_remigen_xlstm/run_20260115-1028\"\n",
    "\n",
    "# For short sequences (< 2048 tokens)\n",
    "generator = MusicGenerator(\n",
    "    model_path=MODEL_PATH,\n",
    "    context_length=8192,  # Same as training\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "converter = MIDIConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ Generating...\n",
      "   Prompt: s-9 o-0 t-35...\n",
      "   Max tokens: 2000\n",
      "   Temperature: 0.9\n",
      "‚úì Generated 2000 tokens (7 bars)\n"
     ]
    }
   ],
   "source": [
    "# Try single-shot generation with larger max_length\n",
    "result = generator.generate(\n",
    "    prompt=\"s-9 o-0 t-35\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=2000,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: ./output/sample_8_ct4096-len100.mid\n",
      "Generated 1999 tokens, 15 bars\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "output_path = \"./output/sample_8_ct4096-len1000.mid\"\n",
    "success = converter.tokens_to_midi(result['tokens'], output_path, clean=True)\n",
    "\n",
    "if success:\n",
    "    print(f\"‚úì Saved: {output_path}\")\n",
    "    print(f\"Generated {result['num_tokens']} tokens, {result['bars']} bars\")\n",
    "else:\n",
    "    print(\"Decoding failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 3056\n",
      "Last 30 tokens: ['d-3', 'v-12', 'd-3', 'v-12', 'i-128', 'p-166', 'd-3', 'v-12', 'b-1', 'd-3', 'v-12', 'd-3', 'v-12', 'd-2', 'd-3', 'd-14', 'd-2', 'd-2', 'd-2', 'p-77', 'd-2', 'v-12', 'o-6', 't-33', 'i-34', 'v-8', 'd-2', 'd-3', 'd-2', 'd-3']\n"
     ]
    }
   ],
   "source": [
    "# Debug: see what token is causing the error\n",
    "tokens = result['tokens'].split()\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(f\"Last 30 tokens: {tokens[-30:]}\")\n",
    "\n",
    "# Find incomplete triplets\n",
    "for i, token in enumerate(tokens[-30:], start=len(tokens)-30):\n",
    "    if token.startswith('p-'):\n",
    "        if i+1 >= len(tokens) or not tokens[i+1].startswith('d-'):\n",
    "            print(f\"Incomplete at {i}: {token} (no duration)\")\n",
    "        elif i+2 >= len(tokens) or not tokens[i+2].startswith('v-'):\n",
    "            print(f\"Incomplete at {i}: {token} {tokens[i+1]} (no velocity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Generate Short Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ Generating...\n",
      "   Prompt: s-9 o-0 t-38...\n",
      "   Max tokens: 1000\n",
      "   Temperature: 0.8\n",
      "‚úì Generated 1000 tokens (8 bars)\n",
      "\n",
      "Generated 1000 tokens, 8 bars\n",
      "Saved to: ./output/test_song.mid\n"
     ]
    }
   ],
   "source": [
    "# Simple generation\n",
    "result = generator.generate(\n",
    "    prompt=\"s-9 o-0 t-38\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=1000,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {result['num_tokens']} tokens, {result['bars']} bars\")\n",
    "\n",
    "# Convert to MIDI\n",
    "output_path = \"./output/test_song.mid\"\n",
    "converter.tokens_to_midi(result['tokens'], output_path)\n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Generate Long Piece (Chunked)\n",
    "\n",
    "This uses **sliding window** approach to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/output/lmd_remigen_xlstm/run_20260115-1028\n",
      "\u001b[32m\u001b[1m   ‚ñÑ‚ñà    ‚ñà‚ñÑ       ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñÑ‚ñà        ‚ñÑ‚ñà  ‚ñÄ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ     ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñÑ  ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ   ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ      ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñÑ ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñÑ   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[1m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñÄ  ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà‚ñå   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ  ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ     ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà‚ñå  ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÄ   ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÄ ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[1m‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ  ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ     ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà‚ñå ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñà‚ñà‚ñÑ  ‚ñÄ‚ñÄ‚ñà‚ñà‚ñà‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñÄ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñÑ  ‚ñà‚ñà‚ñà       ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñÑ ‚ñÄ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[1m  ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñå    ‚ñÑ ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà \n",
      "\u001b[32m\u001b[22m  ‚ñà‚ñà‚ñà    ‚ñà‚ñÄ      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà ‚ñà‚ñÄ   ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÄ    ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÄ   ‚ñÄ‚ñà   ‚ñà‚ñÄ   ‚ñÄ‚ñà   ‚ñà‚ñÄ    ‚ñà‚ñà‚ñà    ‚ñà‚ñÄ  \n",
      "\u001b[32m\u001b[1m                            ‚ñÄ                             ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà                                             \n",
      "\u001b[32m\u001b[22m\n",
      "\u001b[32m\u001b[1mBy Dr. Tristan Behrens\n",
      "\u001b[0m\n",
      "{\n",
      "    \"num_blocks\": 12,\n",
      "    \"embedding_dim\": 256,\n",
      "    \"mlstm_block\": {\n",
      "        \"mlstm\": {\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_block\": {\n",
      "        \"slstm\": {\n",
      "            \"num_heads\": 4,\n",
      "            \"conv1d_kernel_size\": 4\n",
      "        }\n",
      "    },\n",
      "    \"slstm_at\": [\n",
      "        3,\n",
      "        6,\n",
      "        9\n",
      "    ],\n",
      "    \"context_length\": 4096,\n",
      "    \"vocab_size\": 675\n",
      "}\n",
      "Creating xLSTMLMModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2165: FutureWarning: Calling PreTrainedTokenizerFast.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded (context: 4096 tokens)\n",
      "üéµ Long generation (chunked)...\n",
      "   Target: 64 bars\n",
      "   Chunk size: 1024 tokens\n",
      "\n",
      "üìù Iteration 1/2\n",
      "   Context: 26 tokens\n",
      "   Added: 1024 tokens (3 bars)\n",
      "   Total: 1050 tokens (4 bars)\n",
      "\n",
      "üìù Iteration 2/2\n",
      "   Context: 1050 tokens\n",
      "   Added: 1023 tokens (4 bars)\n",
      "   Total: 2073 tokens (8 bars)\n",
      "\n",
      "‚úì Generation complete!\n",
      "   Final: 2073 tokens, 8 bars\n",
      "\n",
      "Saved 8 bars to: ./output/long_song.mid\n"
     ]
    }
   ],
   "source": [
    "# For long generation, use larger context\n",
    "long_generator = MusicGenerator(\n",
    "    model_path=MODEL_PATH,\n",
    "    context_length=4096,  # Larger than training\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "result = long_generator.generate_long(\n",
    "    prompt=\"s-9 o-30 t-33 i-128 p-176 d-6 v-23 o-36 t-33 i-128 p-173 d-6 v-23 o-42 t-33 i-128 p-171 d-6 v-23 b-1 s-9 o-0 t-33 i-4 p-81 d-25\",\n",
    "    temperature=0.8,\n",
    "    target_bars=64,       # Generate 64 bars\n",
    "    chunk_tokens=1024,    # 1024 new tokens per iteration\n",
    "    max_iterations=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save\n",
    "output_path = \"./output/long_song.mid\"\n",
    "converter.tokens_to_midi(result['tokens'], output_path)\n",
    "print(f\"\\nSaved {result['bars']} bars to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: 3509 tokens\n",
      "Last 20 cleaned: ['i-128', 'o-47', 'p-66', 'd-2', 'v-22', 'b-1', 'o-47', 'b-1', 'o-2', 'o-47', 'b-1', 'o-47', 'b-1', 'o-47', 'o-47', 'i-37', 'p-27', 'd-5', 'i-128', 'o-47']\n",
      "Error: AssertionError: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3928866/513666804.py\", line 7, in <module>\n",
      "    midi_obj = converter.decoder.decode_from_token_str_list(cleaned.split())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/midiprocessor/midi_decoding.py\", line 195, in decode_from_token_str_list\n",
      "    midi_obj = self.decode_from_token_list(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/midiprocessor/midi_decoding.py\", line 244, in decode_from_token_list\n",
      "    return enc_remigen_utils.generate_midi_obj_from_remigen_token_list(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/midiprocessor/enc_remigen_utils.py\", line 250, in generate_midi_obj_from_remigen_token_list\n",
      "    assert last_item_type == const.DURATION_ABBR\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "# Add detailed error reporting\n",
    "cleaned = converter.clean_tokens(result['tokens'])\n",
    "print(f\"Cleaned: {len(cleaned.split())} tokens\")\n",
    "print(f\"Last 20 cleaned: {cleaned.split()[-20:]}\")\n",
    "\n",
    "try:\n",
    "    midi_obj = converter.decoder.decode_from_token_str_list(cleaned.split())\n",
    "    print(\"‚úì Decoding successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Batch Generation with Different Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [0.5, 0.8, 1.0, 1.2]\n",
    "output_dir = Path(\"./output/temp_comparison\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = generator.generate(\n",
    "        prompt=\"s-9 o-0 t-35\",\n",
    "        temperature=temp,\n",
    "        max_tokens=2000,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    midi_path = output_dir / f\"temp_{temp:.1f}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], str(midi_path))\n",
    "    print(f\"‚úì Saved: {midi_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Simple API (One Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 songs with one function call\n",
    "outputs = generate_music(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_songs=5,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    output_dir=\"./output/batch\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(outputs)} songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Long Mode with Simple API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate long pieces\n",
    "outputs = generate_music(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_songs=2,\n",
    "    temperature=0.8,\n",
    "    output_dir=\"./output/long_batch\",\n",
    "    long_mode=True,\n",
    "    target_bars=64\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(outputs)} long songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Generated MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: single_shot_test.mid\n",
      "Duration: 28.80s\n",
      "Instruments: 6\n",
      "Total notes: 457\n",
      "  - 27: 113 notes (Program 27)\n",
      "  - 35: 113 notes (Program 35)\n",
      "  - 52: 83 notes (Program 52)\n",
      "  - 53: 45 notes (Program 53)\n",
      "  - 54: 46 notes (Program 54)\n",
      "  - 128: 57 notes (Drums)\n",
      "\n",
      "File: long_song.mid\n",
      "Duration: 33.30s\n",
      "Instruments: 5\n",
      "Total notes: 507\n",
      "  - 4: 57 notes (Program 4)\n",
      "  - 24: 158 notes (Program 24)\n",
      "  - 33: 54 notes (Program 33)\n",
      "  - 49: 59 notes (Program 49)\n",
      "  - 128: 179 notes (Drums)\n",
      "\n",
      "File: test_song.mid\n",
      "Duration: 14.20s\n",
      "Instruments: 4\n",
      "Total notes: 244\n",
      "  - 16: 40 notes (Program 16)\n",
      "  - 25: 170 notes (Program 25)\n",
      "  - 35: 30 notes (Program 35)\n",
      "  - 128: 4 notes (Drums)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "\n",
    "def analyze_midi(midi_path):\n",
    "    midi = pretty_midi.PrettyMIDI(str(midi_path))\n",
    "    \n",
    "    print(f\"File: {midi_path.name}\")\n",
    "    print(f\"Duration: {midi.get_end_time():.2f}s\")\n",
    "    print(f\"Instruments: {len(midi.instruments)}\")\n",
    "    print(f\"Total notes: {sum(len(inst.notes) for inst in midi.instruments)}\")\n",
    "    \n",
    "    for inst in midi.instruments:\n",
    "        inst_type = \"Drums\" if inst.is_drum else f\"Program {inst.program}\"\n",
    "        print(f\"  - {inst.name}: {len(inst.notes)} notes ({inst_type})\")\n",
    "    print()\n",
    "\n",
    "# Analyze all generated files\n",
    "for midi_file in Path(\"./output\").glob(\"**/*.mid\"):\n",
    "    analyze_midi(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Context Length\n",
    "\n",
    "### Training vs Inference:\n",
    "- **Training**: Model was trained with `context_length=2048`\n",
    "- **Inference**: You can use `context_length=4096` or higher\n",
    "  - The model can handle longer sequences\n",
    "  - But memory usage grows quadratically (N¬≤ for mLSTM)\n",
    "\n",
    "### Memory Usage:\n",
    "- `context_length=2048` ‚Üí ~10GB VRAM\n",
    "- `context_length=4096` ‚Üí ~40GB VRAM  \n",
    "- `context_length=8192` ‚Üí ~160GB VRAM (likely OOM)\n",
    "\n",
    "### Solution for Long Generation:\n",
    "Use **sliding window** (implemented in `generate_long()`):\n",
    "- Keep only last N tokens as context\n",
    "- Generate new chunk\n",
    "- Slide window forward\n",
    "- Repeat\n",
    "\n",
    "This keeps memory constant while generating arbitrarily long sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Prompts\n",
    "\n",
    "REMIGEN format: `s-X o-Y t-Z i-A p-B d-C v-D ...`\n",
    "\n",
    "- `s-X`: Signature (time signature)\n",
    "- `o-Y`: Offset (timing)\n",
    "- `t-Z`: Tempo\n",
    "- `i-A`: Instrument\n",
    "- `p-B`: Pitch\n",
    "- `d-C`: Duration\n",
    "- `v-D`: Velocity\n",
    "- `b-1`: Bar marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different starting prompts\n",
    "prompts = [\n",
    "    \"s-9 o-0 t-35\",  # Slow tempo\n",
    "    \"s-9 o-0 t-120\", # Fast tempo\n",
    "    \"s-9 o-0 t-60 i-0\",  # With piano\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    result = generator.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=0.8,\n",
    "        max_tokens=1500,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    midi_path = f\"./output/custom_prompt_{i}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], midi_path)\n",
    "    print(f\"Saved: {midi_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Museformer\n",
    "\n",
    "For your research comparison, you can now:\n",
    "\n",
    "1. Generate same number of pieces from both models\n",
    "2. Use same prompts/seeds\n",
    "3. Compare:\n",
    "   - Musicality\n",
    "   - Coherence over long sequences\n",
    "   - Diversity\n",
    "   - Computational requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate evaluation dataset\n",
    "eval_output = Path(\"./evaluation/xlstm_samples\")\n",
    "eval_output.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for i in range(20):  # Generate 20 samples\n",
    "    result = generator.generate(\n",
    "        prompt=\"s-9 o-0 t-35\",\n",
    "        temperature=0.8,\n",
    "        max_tokens=2048,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    midi_path = eval_output / f\"xlstm_{i:03d}.mid\"\n",
    "    converter.tokens_to_midi(result['tokens'], str(midi_path))\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Generated {i+1}/20 samples\")\n",
    "\n",
    "print(f\"\\n‚úì Evaluation dataset ready: {eval_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
