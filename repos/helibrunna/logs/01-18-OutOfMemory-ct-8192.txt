p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25
 p-60 d-4 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128
 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-15 v-20 p-72 d-15 v-25 p-60 d-12 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15
o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-
15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-1
28 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b
-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-
12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-77 d-15 v-20 p-74 d-15 v-25 p-62 d-12 v-25 i-80 p-65 d-2 v-15 p-53 d-2 v-15 o-12 t-36
i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-53 d-6 v-15 i-128 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-
4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d
-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-53 p-74 d-15 v-20 p-71 d-15 v-25 p-59 d-12 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-3
6 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57
d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-76 d-12 v-20 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-57 d-6 v-17 p-
45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57
d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-15 v-20 p-72 d-15 v-25 p
-60 d-12 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-2
5 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-20 p-69 d-12 v-25 p
-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15
 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164
d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-65 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i
-38 p-53 d-6 v-25 i-53 p-77 d-6 v-20 p-74 d-6 v-25 p-62 d-4 v-25 i-80 p-65 d-6 v-15 p-53 d-6 v-15 i-128 p-164 d-12 v-25 o-18 t-36
 i-38 p-57 d-6 v-25 i-53 p-76 d-12 v-20 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-2
5 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-53 p-74 d-12 v-20 p-71 d-12 v-25 p-59 d-8
 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 o-42 t
-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-53 d-12 v-25 i-53 p-77 d-33 v-25 p-72 d-33 v-25 p
-69 d-33 v-25 i-80 p-53 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 i-128 p-167 d-12 v-25 p-1
66 d-12 v-25 o-18 t-36 i-38 p-53 d-12 v-25 i-80 p-53 d-12 v-17 o-24 t-36 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-65 d-6 v-25 i-80
p-65 d-6 v-17 o-36 t-36 i-38 p-53 d-6 v-25 i-80 p-53 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-65 d-6 v-25
i-80 p-65 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-52 d-12 v-25 i-80 p-52 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-64 d-6 v-25 i-
80 p-64 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-52 d-12 v-25 i-80 p-52 d-12 v-17 o-24 t-36 i-50 p-84 d-9
v-25 p-72 d-9 v-25 i-53 p-76 d-27 v-25 p-72 d-27 v-25 p-69 d-27 v-25 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-64 d-6 v-25 i-80 p-64
 d-6 v-17 o-33 t-36 i-50 p-83 d-6 v-25 p-71 d-6 v-25 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-52 d-6 v-17 i-128 p-167 d-12 v-25 p-166
d-12 v-25 o-39 t-36 i-50 p-81 d-9 v-25 p-69 d-9 v-25 o-42 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d
-12 v-25 i-50 p-83 d-15 v-25 p-71 d-15 v-25 i-80 p-57 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-57 d-6
v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-50 p-84 d-6 v-25 p-72 d-6 v-25 i-80 p-57 d-6 v-17 o-24
t-36 i-38 p-57 d-6 v-25 i-50 p-81 d-27 v-25 p-69 d-27 v-25 i-80 p-57 d-6 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-57 d-6 v-25
i-80 p-57 d-6 v-17 o-36 t-36 i-38 p-57 d-12 v-25 i-53 p-79 d-12 v-25 p-76 d-12 v-25 p-72 d-12 v-25 i-80 p-57 d-12 v-17 i-128 p-16
7 d-12 v-25 p-166 d-12 v-25 b-1 s-9 o-0 t-36 i-38 p-50 d-12 v-25 i-53 p-77 d-27 v-25 p-74 d-27 v-25 p-69 d-27 v-25 i-80 p-50 d-12
 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-62 d-6 v-25 i-80 p-62 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38
p-50 d-12 v-25 i-80 p-50 d-12 v-17 o-24 t-36 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-62 d-6 v-25 i-50 p-69 d-4 v-25 p-57 d-4 v-25
i-80 p-62 d-6 v-17 o-34 t-36 i-50 p-72 d-4 v-25 p-60 d-4 v-25 o-36 t-36 i-38 p-50 d-6 v-25 i-50 p-74 d-4 v-25 p-62 d-4 v-25 i-80
p-50 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-40 t-36 i-50 p-75 d-4 v-25 p-63 d-4 v-25 o-42 t-36 i-38 p-62 d-6 v-25 i-80
p-62 d-6 v-17 o-44 t-36 i-50 p-74 d-4 v-25 p-62 d-4 v-25 o-46 t-36 i-50 p-72 d-25 v-25 p-60 d-25 v-25 b-1 s-9 o-0 t-36 i-38 p-53
d-12 v-25 i-53 p-77 d-27 v-25 p-72 d-27 v-25 p-69 d-27 v-25 i-80 p-53 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-65 d-6 v-2
5 i-80 p-65 d-6 v-17 i-95 p-76 d-36 v-25 p-72 d-36 v-25 p-69 d-36 v-25 p-64 d-36 v-25 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18
t-36 i-38 p-53 d-12 v-25 i-80 p-53 d-12 v-17 o-24 t-36 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 o-33
 t-36 i-50 p-75 d-3 v-25 p-63 d-3 v-25 o-36 t-36 i-38 p-53 d-6 v-25 i-50 p-74 d-3 v-25 p-62 d-3 v-25 i-80 p-53 d-6 v-17 i-128 p-1
67 d-12 v-25 p-166 d-12 v-25 o-39 t-36 i-50 p-72 d-7 v-25 p-60 d-7 v-25 o-42 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 b-1 s-9 o
-0 t-36 i-38 p-52 d-12 v-25 i-50 p-76 d-18 v-25 p-64 d-18 v-25 i-53 p-76 d-27 v-25 p-72 d-27 v-25 p-69 d-27 v-25 i-80 p-52 d-12 v
-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-
52 d-12 v-25 i-80 p-52 d-12 v-17 o-24 t-36 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-64 d-6 v-25 i-
50 p-81 d-31 v-25 p-69 d-31 v-25 i-80 p-64 d-6 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-52 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d
-12 v-25 o-42 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d
-27 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-
36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25
 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v
-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-170 d-3 v-25 o-30 t-36 i-128
p-170 d-3 v-25 o-33 t-36 i-128 p-170 d-3 v-25 o-36 t-36 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-170 d-3 v-25 o-42
t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-27 v-25 p-67 d-27 v-25 p-60 d-27 v-25 p-55 d
-27 v-25 i-53 p-84 d-4 v-25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d
-4 v-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d
-3 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36
i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-71 d-9 v-25 p-67 d-9 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-170 d-3 v-
25 o-30 t-36 i-128 p-170 d-3 v-25 o-33 t-36 i-53 p-71 d-3 v-25 p-67 d-3 v-25 i-128 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-
69 d-6 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-170 d-3 v-25 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-
170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25 i-50 p-60 d-27 v-25 i-53 p-84 d-4 v
-25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-
128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25
o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-2
4 t-36 i-53 p-76 d-9 v-25 p-69 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170
d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-76 d-3 v-25 p-69 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3
v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-6 v-25 p-170 d-3 v-2
5 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-27 v-25 p-67 d-27 v-25 p-60 d-27 v-25
 p-55 d-27 v-25 i-50 p-62 d-27 v-25 i-53 p-84 d-4 v-25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-
3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25
p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-12
8 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-71 d-9 v-25 p-67 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p-
163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-71 d-3
 v-25 p-67 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-163 d-1
2 v-25 o-39 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25
 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25 i-50 p-64 d-27 v-25 i-53 p-84 d-4 v-25 p-79 d-4
 v-25 p-64 d-27 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25
 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-167 d-12 v-
25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25
 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-76 d-9 v-25 p-69 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p-163 d-12 v-25 o-
27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-76 d-3 v-25 p-69 d-3 v
-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-167 d-12 v-25 p-166 d-1
2 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-2
5 b-1 s-9 o-0 t-36 i-0 p-72 d-27 v-25 p-67 d-27 v-25 p-60 d-27 v-25 p-55 d-27 v-25 i-50 p-66 d-27 v-25 i-53 p-84 d-4 v-25 p-79 d-
4 v-25 p-66 d-27 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-2
5 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-167 d-12 v
-25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-2
5 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-71 d-9 v-25 p-67 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p-163 d-12 v-25 o
-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-71 d-3 v-25 p-67 d-3
v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-167 d-12 v-25 p-166 d-
12 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-45 t-36 i-1
28 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25 i-50 p-67 d-27 v-25 i-53 p-84
d-4 v-25 p-79 d-4 v-25 p-67 d-27 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v
-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v
-25 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-1
28 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-76 d-9 v-25 p-69 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p
-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-76 d-
3 v-25 p-69 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-167 d-
12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-
128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-12 v-25 p-67 d-12 v-25 p-60 d-12 v-25 p-55 d-12 v-25 i-50 p-69 d-14 v-25 i-53 p-84
 d-4 v-25 p-79 d-4 v-25 p-66 d-14 v-25 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4
 v-25 o-12 t-36 i-0 p-72 d-8 v-25 p-67 d-8 v-25 p-60 d-8 v-25 p-55 d-8 v-25 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-167 d-12 v-2
5 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 o-30 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 i-53 p-67
 d-3 v-25 o-33 t-36 i-50 p-81 d-3 v-25 p-69 d-3 v-25 i-53 p-69 d-3 v-25 o-36 t-36 i-50 p-84 d-3 v-25 p-72 d-3 v-25 i-53 p-72 d-3
v-25 o-39 t-36 i-50 p-83 d-3 v-25 p-71 d-3 v-25 i-53 p-71 d-3 v-25 o-42 t-36 i-50 p-81 d-3 v-25 p-69 d-3 v-25 i-53 p-69 d-3 v-25
o-45 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 i-53 p-67 d-3 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-12 v-25 p-45 d-6 v-25 i-50 p-81 d-27 v
-25 p-69 d-27 v-25 i-53 p-69 d-27 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-
6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t
-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-
17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-1
5 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-
25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25
i-50 p-72 d-15 v-25 p-60 d-15 v-25 i-53 p-60 d-15 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6
 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6
v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25
 i-50 p-74 d-12 v-25 p-62 d-12 v-25 i-53 p-62 d-12 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d
-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-53 p-
64 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-72 d-12 v-25 p-60 d-12 v-25 i-53 p-60 d-12 v-25
i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4
 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-50 p-69 d-27 v-25 p-57 d-27 v-25 i-53 p-57 d-27 v-25 i-80
 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-
69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p
-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-16
3 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-2
5 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d
-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-16
4 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-
38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-
25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-
128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-53 p-64 d-6 v-25 i-80 p-64 d-
4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-53 p-67 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4
 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-53
p-69 d-31 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-1
5 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-1
2 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25
 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-60 d-2
v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-3
6 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128
p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-
65 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p
-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-50 p-87 d-6 v-25 p-75 d-6 v-25 i-53 p-75 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-
128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-86 d-6 v-25 p-74 d-6 v-25 i-53 p-74 d-6 v-25 i-80 p-64 d-
4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-84 d-6 v-25 p-72 d-6 v-25 i-53 p-72 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4
 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-53
p-69 d-31 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-1
5 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-1
2 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25
 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-60 d-2
v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-3
6 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128
p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-
65 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p
-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p
-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25
 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-2
5 p-45 d-6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-
25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-25 p-
69 d-12 v-25 p-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-
80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-53 p-76 d-12 v-25 p-72 d-12 v-25 p-60 d
-8 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60
 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v
-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-12 v-25 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-69
 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-
163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-74 d-18 v-25 p-69 d-18 v-25 p-57 d-18 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53
 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-1
2 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v
-17 p-52 d-4 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-2
5 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4
 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45 d-
6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 o-12 t-36 i
-38 p-57 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-12 v-25 p-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d
-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i
-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25
 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57
d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-
42 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-12 v-25 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d
-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-
53 p-77 d-12 v-25 p-74 d-12 v-25 p-62 d-8 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d
-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-
6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-74 d-1
8 v-25 p-71 d-18 v-25 p-59 d-14 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-6
4 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42
 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-76 d-6 v-25 p-
72 d-6 v-25 p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-25 p
-72 d-6 v-25 p-60 d-4 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-12 v-25 p-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57
d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60
d-6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-6
0 d-6 v-25 i-53 p-76 d-6 v-25 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-72 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72
 d-6 v-25 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-57
d-6 v-25 i-53 p-76 d-12 v-25 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-
80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-74 d-18 v-25 p-69 d-18 v-25 p-57 d-18 v-2
5 i-80 p-65 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12
 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17
 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v
-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0
 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 i-128 p-16
3 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-1
2 v-20 p-69 d-12 v-25 p-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-
6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-53 p-76 d-12 v-20 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-72 d
-8 v-17 p-60 d-8 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6
 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42
t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-12 v-20 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p
-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-77 d-12 v-20 p-74 d-12 v-2
5 p-62 d-8 v-25 i-80 p-65 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v
-25 p-166 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17
o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-74 d-18 v-20 p-71 d-18 v-25 p-59 d-14 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-163 d-12
v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17
i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-53 d-
12 v-25 i-53 p-77 d-33 v-25 p-72 d-33 v-25 p-69 d-33 v-25 i-80 p-53 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-65 d-6 v-25
i-80 p-65 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-53 d-12 v-25 i-80 p-53 d-12 v-17 o-24 t-36 i-128 p-163
d-12 v-25 o-30 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 o-36 t-36 i-38 p-53 d-6 v-25 i-80 p-53 d-6 v-17 i-128 p-167 d-12 v-25 p
-166 d-12 v-25 o-42 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-52 d-12 v-25 i-80 p-52 d-12 v-17 i-128 p-1
63 d-12 v-25 o-12 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-52 d-12 v-25
i-80 p-52 d-12 v-17 o-24 t-36 i-53 p-76 d-18 v-25 p-72 d-18 v-25 p-69 d-18 v-25 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-64 d-6 v-2
5 i-80 p-64 d-6 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-52 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-64 d-
6 v-25 i-50 p-84 d-12 v-25 p-72 d-12 v-25 i-80 p-64 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-12 v-25 i-53 p-76 d-24 v-25 p-72 d-24 v
-25 p-69 d-24 v-25 i-80 p-57 d-12 v-17 i-128 p-163 d-12 v-25 o-6 t-36 i-50 p-83 d-6 v-25 p-71 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-
25 i-50 p-81 d-3 v-25 p-69 d-3 v-25 i-80 p-57 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-15 t-36 i-50 p-79 d-3 v-25 p-67 d-
3 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-50 p-81 d-15 v-25 p-69 d-15 v-25 i-80 p-57 d-6 v-17 o-24 t-36 i-38 p-57 d-6 v-25 i-80 p-57
d-6 v-17 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-57 d-6 v-25 i-80 p-57 d-6 v-17 o-36 t-36 i-38 p-57 d-12 v-25 i-53 p-79 d-12 v-25
p-76 d-12 v-25 p-72 d-12 v-25 i-80 p-57 d-12 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-50 p-75 d-12 v-25 p-63 d-12 v
-25 b-1 s-9 o-0 t-36 i-38 p-50 d-12 v-25 i-53 p-77 d-27 v-25 p-74 d-27 v-25 p-69 d-27 v-25 i-80 p-50 d-12 v-17 i-128 p-163 d-12 v
-25 o-6 t-36 i-50 p-74 d-3 v-25 p-62 d-3 v-25 o-9 t-36 i-50 p-72 d-13 v-25 p-60 d-13 v-25 o-12 t-36 i-38 p-62 d-6 v-25 i-80 p-62
d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-50 d-12 v-25 i-80 p-50 d-12 v-17 o-24 t-36 i-50 p-75 d-3 v-25 p-6
3 d-3 v-25 i-128 p-163 d-12 v-25 o-27 t-36 i-50 p-74 d-3 v-25 p-62 d-3 v-25 o-30 t-36 i-38 p-62 d-6 v-25 i-50 p-72 d-12 v-25 p-60
 d-12 v-25 i-80 p-62 d-6 v-17 o-36 t-36 i-38 p-50 d-6 v-25 i-80 p-50 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-39 t-36 i-5
0 p-75 d-3 v-25 p-63 d-3 v-25 o-42 t-36 i-38 p-62 d-6 v-25 i-50 p-72 d-13 v-25 p-60 d-13 v-25 i-80 p-62 d-6 v-17 b-1 s-9 o-0 t-36
 i-38 p-53 d-12 v-25 i-53 p-77 d-27 v-25 p-72 d-27 v-25 p-69 d-27 v-25 i-80 p-53 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p
-65 d-6 v-25 i-50 p-72 d-6 v-25 p-60 d-6 v-25 i-80 p-65 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-53 d-12 v
-25 i-50 p-76 d-12 v-25 p-64 d-12 v-25 i-80 p-53 d-12 v-17 o-24 t-36 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-65 d-6 v-25 i-50 p-74
 d-6 v-25 p-62 d-6 v-25 i-80 p-65 d-6 v-17 o-36 t-36 i-38 p-53 d-6 v-25 i-50 p-76 d-18 v-25 p-64 d-18 v-25 i-80 p-53 d-6 v-17 i-1
28 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-52 d-12 v-25 i-53 p-76
 d-27 v-25 p-72 d-27 v-25 p-69 d-27 v-25 i-80 p-52 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-1
7 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-18 t-36 i-38 p-52 d-12 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-80 p-52 d-12 v-17 o-24 t
-36 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-128 p-163 d-12 v-25 o-30 t-36 i-38 p-64 d-6 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-80 p
-64 d-6 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-52 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 o-42 t-36 i-38 p-64 d-6 v-25 i
-80 p-64 d-6 v-17 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-
25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-1
28 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o
-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24
 t-36 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-170 d-3 v-25 o-30 t-36 i-128 p-170 d-3 v-25 o-33 t-36 i-128 p-170 d-
3 v-25 o-36 t-36 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-170 d-3 v-25 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-1
28 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-27 v-25 p-67 d-27 v-25 p-60 d-27 v-25 p-55 d-27 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-
25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-1
28 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o
-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24
 t-36 i-53 p-71 d-9 v-25 p-67 d-9 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-170 d-3 v-25 o-30 t-36 i-128 p-170
d-3 v-25 o-33 t-36 i-53 p-71 d-3 v-25 p-67 d-3 v-25 i-128 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d
-3 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-170 d-3 v-25 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25 b-1 s-9 o-0
t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25 i-50 p-60 d-27 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-25 p-79 d-
4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-128 p-170 d
-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-15 t-36 i
-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53
 p-76 d-9 v-25 p-69 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-
30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-76 d-3 v-25 p-69 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t
-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-42 t-36
 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-27 v-25 p-67 d-27 v-25 p-60 d-27 v-25 p-55 d-27
v-25 i-50 p-62 d-27 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-25 p-79 d-4 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170
 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-
25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i
-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-71 d-9 v-25 p-67 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25
 p-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-71
d-3 v-25 p-67 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-163
d-12 v-25 o-39 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v
-25 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25 i-50 p-64 d-27 v-25 i-53 p-88 d-4 v-25 p-84
d-4 v-25 p-79 d-4 v-25 p-64 d-27 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v
-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v
-25 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-1
28 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-76 d-9 v-25 p-69 d-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p
-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-76 d-
3 v-25 p-69 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-167 d-
12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-
128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-27 v-25 p-67 d-27 v-25 p-60 d-27 v-25 p-55 d-27 v-25 i-50 p-66 d-27 v-25 i-53 p-88
 d-4 v-25 p-84 d-4 v-25 p-79 d-4 v-25 p-66 d-27 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36 i-128 p-170 d-3 v-25 o-6 t-36
i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-
128 p-170 d-3 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-2
5 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-71 d-9 v-25 p-67 d-9 v-25 i-128 p-208 d-3 v-25 p
-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-33 t-
36 i-53 p-71 d-3 v-25 p-67 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-6 v-25 i-128 p-170 d-
3 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-42 t-36 i-128 p-208 d-3 v-
25 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-69 d-27 v-25 p-64 d-27 v-25 p-57 d-27 v-25 p-52 d-27 v-25
 i-50 p-67 d-27 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-25 p-79 d-4 v-25 p-67 d-27 v-25 i-128 p-170 d-3 v-25 p-163 d-12 v-25 o-3 t-36
i-128 p-170 d-3 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 i-128 p-170 d-3 v-25 o-9 t-36 i-128 p-170 d-3 v-25 o-12 t-36 i-53
p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-170 d-3 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-7
6 d-2 v-25 i-128 p-170 d-3 v-25 o-18 t-36 i-128 p-170 d-3 v-25 o-21 t-36 i-128 p-170 d-3 v-25 o-24 t-36 i-53 p-76 d-9 v-25 p-69 d
-9 v-25 i-128 p-208 d-3 v-25 p-170 d-3 v-25 p-163 d-12 v-25 o-27 t-36 i-128 p-208 d-3 v-25 p-170 d-3 v-25 o-30 t-36 i-128 p-208 d
-3 v-25 p-170 d-3 v-25 o-33 t-36 i-53 p-76 d-3 v-25 p-69 d-3 v-25 i-128 p-208 d-6 v-25 p-170 d-3 v-25 o-36 t-36 i-53 p-72 d-6 v-2
5 p-69 d-6 v-25 i-128 p-170 d-3 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-39 t-36 i-128 p-208 d-6 v-25 p-170 d-3 v-2
5 o-42 t-36 i-128 p-170 d-3 v-25 o-45 t-36 i-128 p-170 d-3 v-25 b-1 s-9 o-0 t-36 i-0 p-72 d-12 v-25 p-67 d-12 v-25 p-60 d-12 v-25
 p-55 d-12 v-25 i-50 p-69 d-14 v-25 i-53 p-88 d-4 v-25 p-84 d-4 v-25 p-79 d-4 v-25 p-66 d-14 v-25 i-128 p-167 d-12 v-25 p-166 d-1
2 v-25 p-163 d-12 v-25 o-6 t-36 i-53 p-81 d-4 v-25 p-76 d-4 v-25 o-12 t-36 i-0 p-72 d-8 v-25 p-67 d-8 v-25 p-60 d-8 v-25 p-55 d-8
 v-25 i-53 p-81 d-2 v-25 p-76 d-2 v-25 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-163 d-12 v-25 o-15 t-36 i-53 p-81 d-2 v-25 p-76 d-
2 v-25 o-30 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 i-53 p-67 d-3 v-25 o-33 t-36 i-50 p-81 d-3 v-25 p-69 d-3 v-25 i-53 p-69 d-3 v-2
5 o-36 t-36 i-50 p-84 d-3 v-25 p-72 d-3 v-25 i-53 p-72 d-3 v-25 o-39 t-36 i-50 p-83 d-3 v-25 p-71 d-3 v-25 i-53 p-71 d-3 v-25 o-4
2 t-36 i-50 p-81 d-3 v-25 p-69 d-3 v-25 i-53 p-69 d-3 v-25 o-45 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 i-53 p-67 d-3 v-25 b-1 s-9
o-0 t-36 i-38 p-57 d-12 v-25 p-45 d-6 v-25 i-50 p-81 d-27 v-25 p-69 d-27 v-25 i-53 p-69 d-27 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-1
5 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i
-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15
p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38
p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d
-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57
d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-50 p-72 d-15 v-25 p-60 d-15 v-25 i-53 p-60 d-15 v-25 i-80 p-65 d-8 v
-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-1
5 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p
-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-50 p-74 d-12 v-25 p-62 d-12 v-25 i-53 p-62 d-12 v-25 i-80 p-69 d-4
v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36
i-38 p-52 d-6 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-53 p-64 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v
-25 i-50 p-72 d-12 v-25 p-60 d-12 v-25 i-53 p-60 d-12 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25
 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25
i-50 p-69 d-27 v-25 p-57 d-27 v-25 i-53 p-57 d-27 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t
-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164
d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25
i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v
-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-
25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-3
8 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2
v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d
-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24
t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50
p-76 d-6 v-25 p-64 d-6 v-25 i-53 p-64 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-79 d-6 v-25 p
-67 d-6 v-25 i-53 p-67 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36
i-38 p-57 d-4 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-53 p-69 d-31 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38
p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-5
7 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-
80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-2
5 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-1
28 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36
 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65
d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164
d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-50 p-87 d-6 v-25 p-75 d-6
v-25 i-53 p-75 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50
p-86 d-6 v-25 p-74 d-6 v-25 i-53 p-74 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-84 d-6 v-25 p
-72 d-6 v-25 i-53 p-72 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36
i-38 p-57 d-4 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-53 p-69 d-31 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38
p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-5
7 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-
80 p-69 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-2
5 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-1
28 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36
 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65
d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164
d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4
v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6
v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-6
9 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p
-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-
166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36
 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72
 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-1
2 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15
b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6
 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15
p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17
 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38
 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-
25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v
-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38
 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-2
5 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-12
8 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36
t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-5
7 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-
53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53
 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d
-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4
 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36
 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-
4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d
-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-1
67 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2
 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6
 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17
i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15
 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-3
6 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15
 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-8
0 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25
 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-12
8 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36
i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25
 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-
38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-6
0 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60
 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-4
2 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p
-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-5
3 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-
12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-2
5 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4
 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-
36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-53 d-12 v-25 i-53 p-77 d-33 v-25 p-72 d-33 v-25 p-
69 d-33 v-25 i-80 p-53 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 i-128 p-167 d-12 v-25 p-16
6 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-53 d-12 v-25 i-80 p-53 d-12 v-17 o-24 t-36 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-3
0 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 o-36 t-36 i-38 p-53 d-6 v-25 i-80 p-53 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-2
5 p-164 d-12 v-25 o-42 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-52 d-12 v-25 i-80 p-52 d-12 v-17 i-128
p-164 d-12 v-25 p-163 d-12 v-25 o-12 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12
v-25 o-18 t-36 i-38 p-52 d-12 v-25 i-80 p-52 d-12 v-17 o-24 t-36 i-53 p-76 d-18 v-25 p-72 d-18 v-25 p-69 d-18 v-25 i-128 p-164 d-
12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-52 d-6 v-17 i-128 p-1
67 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-64 d-6 v-25 i-50 p-84 d-12 v-25 p-72 d-12 v-25 i-80 p-64 d-6 v-17 b
-1 s-9 o-0 t-36 i-38 p-57 d-12 v-25 i-53 p-76 d-24 v-25 p-72 d-24 v-25 p-69 d-24 v-25 i-80 p-57 d-12 v-17 i-128 p-163 d-12 v-25 o
-6 t-36 i-50 p-83 d-6 v-25 p-71 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-50 p-81 d-3 v-25 p-69 d-3 v-25 i-80 p-57 d-6 v-17 i-128 p
-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-15 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-50 p-81
d-15 v-25 p-69 d-15 v-25 i-80 p-57 d-6 v-17 o-24 t-36 i-38 p-57 d-6 v-25 i-80 p-57 d-6 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25
 o-30 t-36 i-38 p-57 d-6 v-25 i-80 p-57 d-6 v-17 o-36 t-36 i-38 p-57 d-12 v-25 i-53 p-79 d-12 v-25 p-76 d-12 v-25 p-72 d-12 v-25
i-80 p-57 d-12 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-50 p-75 d-12 v-25 p-63 d-12 v-25 b-1 s-9 o-
0 t-36 i-38 p-50 d-12 v-25 i-53 p-77 d-27 v-25 p-74 d-27 v-25 p-69 d-27 v-25 i-80 p-50 d-12 v-17 i-128 p-164 d-12 v-25 p-163 d-12
 v-25 o-6 t-36 i-50 p-74 d-3 v-25 p-62 d-3 v-25 o-9 t-36 i-50 p-72 d-13 v-25 p-60 d-13 v-25 o-12 t-36 i-38 p-62 d-6 v-25 i-80 p-6
2 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-50 d-12 v-25 i-80 p-50 d-12 v-17 o-24 t-36 i-50
 p-75 d-3 v-25 p-63 d-3 v-25 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-27 t-36 i-50 p-74 d-3 v-25 p-62 d-3 v-25 o-30 t-36 i-38 p-62
 d-6 v-25 i-50 p-72 d-12 v-25 p-60 d-12 v-25 i-80 p-62 d-6 v-17 o-36 t-36 i-38 p-50 d-6 v-25 i-80 p-50 d-6 v-17 i-128 p-167 d-12
v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-39 t-36 i-50 p-75 d-3 v-25 p-63 d-3 v-25 o-42 t-36 i-38 p-62 d-6 v-25 i-50 p-72 d-13 v-25
p-60 d-13 v-25 i-80 p-62 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-53 d-12 v-25 i-53 p-77 d-27 v-25 p-72 d-27 v-25 p-69 d-27 v-25 i-80 p-5
3 d-12 v-17 i-128 p-163 d-12 v-25 o-12 t-36 i-38 p-65 d-6 v-25 i-50 p-72 d-6 v-25 p-60 d-6 v-25 i-80 p-65 d-6 v-17 i-128 p-167 d-
12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-53 d-12 v-25 i-50 p-76 d-12 v-25 p-64 d-12 v-25 i-80 p-53 d-12 v-17 o-24
 t-36 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-65 d-6 v-25 i-50 p-74 d-6 v-25 p-62 d-6 v-25 i-80 p-65 d-6 v-17 o-36
 t-36 i-38 p-53 d-6 v-25 i-50 p-76 d-18 v-25 p-64 d-18 v-25 i-80 p-53 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v
-25 o-42 t-36 i-38 p-65 d-6 v-25 i-80 p-65 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-52 d-12 v-25 i-53 p-76 d-27 v-25 p-72 d-27 v-25 p-69
d-27 v-25 i-80 p-52 d-12 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-12 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 i-128 p-167 d
-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-52 d-12 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-80 p-52 d-12 v-17 o-24
t-36 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-64 d-6 v-25 i-50 p-81 d-31 v-25 p-69
 d-31 v-25 i-80 p-64 d-6 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-52 d-6 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-
25 o-42 t-36 i-38 p-64 d-6 v-25 i-80 p-64 d-6 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6
v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-1
7 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-
15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-
38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-5
7 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-
57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v
-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-
65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d
-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-16
3 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o-36 t-36 i-38 p-52 d-6 v-25 i-80
p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-8
0 p-69 d-4 v-17 p-57 d-4 v-17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6
v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-1
7 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-
15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-
38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-5
7 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-
57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v
-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-
65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d
-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-16
3 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-75 d-3 v-25 p-63 d-3 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o
-33 t-36 i-50 p-74 d-3 v-25 p-62 d-3 v-25 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-72 d-3 v-25 p-60 d-3 v-25 i-80 p-64 d-4 v-17 p-52 d
-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-39 t-36 i-50 p-74 d-13 v-25 p-62 d-13 v-25 o-42 t-
36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-8
0 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-50 p-75 d-6 v-25 p-63 d-6 v-25 o-
12 t-36 i-38 p-57 d-6 v-25 i-50 p-72 d-18 v-25 p-60 d-18 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v
-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60
 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15
p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-1
66 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-
0 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-80
 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v
-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4
v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6
v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d
-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-128 p-163 d-12 v-25 o-1
2 t-36 i-53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8 v-25 i-128 p-164 d-12 v-25 o-24 t-36 i-53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8
 v-25 i-128 p-164 d-12 v-25 o-36 t-36 i-53 p-69 d-12 v-25 p-64 d-8 v-20 p-57 d-8 v-25 i-128 p-164 d-12 v-25 b-1 s-9 o-0 t-36 i-53
 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-128 p-164 d-12 v-25 o-6 t-36 i-53 p-72 d-15 v-25 p-69 d-12 v-20 p-60 d-12 v-25 o-12
t-36 i-128 p-164 d-12 v-25 o-24 t-36 i-50 p-81 d-12 v-25 p-69 d-12 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-128 p-16
4 d-12 v-25 o-30 t-36 i-53 p-71 d-15 v-25 p-64 d-15 v-20 p-59 d-12 v-25 o-34 t-36 i-50 p-76 d-23 v-25 p-64 d-23 v-25 o-36 t-36 i-
128 p-164 d-12 v-25 b-1 s-9 o-0 t-36 i-53 p-76 d-4 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-128 p-163 d-12 v-25 o-6 t-36 i-53 p-76 d-12
 v-20 p-72 d-15 v-25 p-60 d-12 v-25 o-12 t-36 i-128 p-164 d-12 v-25 o-24 t-36 i-53 p-76 d-8 v-20 p-72 d-12 v-25 p-60 d-8 v-25 i-1
28 p-164 d-12 v-25 o-36 t-36 i-53 p-72 d-12 v-20 p-69 d-12 v-25 p-57 d-12 v-25 i-128 p-164 d-12 v-25 b-1 s-9 o-0 t-36 i-53 p-76 d
-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-128 p-164 d-12 v-25 o-6 t-36 i-53 p-77 d-15 v-20 p-74 d-15 v-25 p-62 d-12 v-25 o-12 t-36 i-
128 p-164 d-12 v-25 o-24 t-36 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-128 p-164 d-12 v-25 o-30 t-36 i-50 p-67 d-6 v-25 p
-55 d-6 v-25 i-53 p-74 d-12 v-20 p-71 d-12 v-25 p-59 d-8 v-25 o-36 t-36 i-50 p-69 d-6 v-25 p-57 d-6 v-25 i-128 p-164 d-12 v-25 o-
42 t-36 i-50 p-72 d-28 v-25 p-60 d-28 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57 d-4 v-25 b-1 s-9 o-0 t-36 i-53 p-72 d-6 v-25 p-6
9 d-4 v-20 p-60 d-4 v-25 i-128 p-163 d-12 v-25 o-6 t-36 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 o-12 t-36 i-53 p-69 d-6 v-
25 p-64 d-4 v-20 p-57 d-4 v-25 i-128 p-164 d-12 v-25 o-18 t-36 i-53 p-72 d-15 v-25 p-69 d-12 v-20 p-60 d-12 v-25 o-24 t-36 i-128
p-164 d-12 v-25 o-36 t-36 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-128 p-164 d-12 v-25 o-42 t-36 i-53 p-69 d-6 v-25 p-64
d-4 v-20 p-57 d-4 v-25 b-1 s-9 o-0 t-36 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-128 p-164 d-12 v-25 o-6 t-36 i-53 p-74 d
-15 v-25 p-69 d-12 v-20 p-62 d-12 v-25 o-12 t-36 i-128 p-164 d-12 v-25 o-24 t-36 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i
-128 p-164 d-12 v-25 o-30 t-36 i-50 p-67 d-6 v-25 p-55 d-6 v-25 i-53 p-71 d-15 v-25 p-67 d-12 v-20 p-59 d-12 v-25 o-36 t-36 i-50
p-69 d-6 v-25 p-57 d-6 v-25 i-128 p-164 d-12 v-25 o-42 t-36 i-50 p-72 d-21 v-25 p-60 d-21 v-25 b-1 s-9 o-0 t-36 i-53 p-72 d-12 v-
25 p-69 d-8 v-20 p-60 d-8 v-25 i-128 p-163 d-12 v-25 o-12 t-36 i-53 p-69 d-6 v-25 p-64 d-4 v-20 p-57 d-4 v-25 i-128 p-164 d-12 v-
25 o-18 t-36 i-53 p-72 d-15 v-25 p-69 d-12 v-20 p-60 d-12 v-25 o-24 t-36 i-128 p-164 d-12 v-25 o-36 t-36 i-53 p-69 d-12 v-25 p-64
 d-8 v-20 p-57 d-8 v-25 i-128 p-164 d-12 v-25 b-1 s-9 o-0 t-36 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-128 p-164 d-12 v-
25 o-6 t-36 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 o-12 t-36 i-53 p-74 d-6 v-25 p-69 d-4 v-20 p-62 d-4 v-25 i-128 p-164 d
-12 v-25 o-18 t-36 i-50 p-75 d-3 v-25 p-63 d-3 v-25 i-53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8 v-25 o-21 t-36 i-50 p-74 d-12 v-25
 p-62 d-12 v-25 o-24 t-36 i-128 p-164 d-12 v-25 o-30 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 i-53 p-71 d-12 v-25 p-67 d-8 v-20 p-59
 d-8 v-25 o-33 t-36 i-50 p-81 d-3 v-25 p-69 d-3 v-25 o-36 t-36 i-50 p-84 d-3 v-25 p-72 d-3 v-25 i-128 p-164 d-12 v-25 o-39 t-36 i
-50 p-83 d-3 v-25 p-71 d-3 v-25 o-42 t-36 i-50 p-81 d-3 v-25 p-69 d-3 v-25 o-45 t-36 i-50 p-79 d-3 v-25 p-67 d-3 v-25 b-1 s-9 o-0
 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-50 p-81 d-27 v-25 p-69 d-27 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-
163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8 v-25 i-80 p-69
d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69
 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8 v-25 i-80 p-72 d-8
v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v
-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-12 v-25 p-64 d-8 v-20 p-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i
-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15
p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-50 p-72 d-15 v-25 p-60 d-15 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-
25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-72 d-15 v-25 p-69 d-
12 v-20 p-60 d-12 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-
15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i
-50 p-74 d-12 v-25 p-62 d-12 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20
p-60 d-4 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-76 d-6 v
-25 p-64 d-6 v-25 i-53 p-71 d-15 v-25 p-64 d-15 v-20 p-59 d-12 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o-36 t-
36 i-38 p-52 d-6 v-25 i-50 p-72 d-12 v-25 p-60 d-12 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-25 p-
166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36
 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-50 p-69 d-27 v-25 p-57 d-27 v-25 i-53 p-76 d-4 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-57 d-6
 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-12 v-20 p-72 d-15 v-25 p-60 d-12
v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-3
6 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-53 p-76 d-8 v-20
 p-72 d-12 v-25 p-60 d-8 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25
 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-20 p-69 d-12 v-25 p-5
7 d-12 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i
-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25
p-60 d-4 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-77 d-15 v
-20 p-74 d-15 v-25 p-62 d-12 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80
p-65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57
 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-64
d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-53 p
-74 d-12 v-20 p-71 d-12 v-25 p-59 d-8 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o-36 t-36 i-38 p-52 d-6 v-25 i-5
0 p-79 d-6 v-25 p-67 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-
25 o-42 t-36 i-38 p-57 d-4 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57 d-4 v-25 i-80 p-69 d-4 v
-17 p-57 d-4 v-17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-
4 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d
-4 v-20 p-60 d-4 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-6 v-25 p-64 d-4 v-20 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-1
7 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-15 v-25 p-69 d-12 v-20 p-60 d-12
 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17
i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o
-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25
 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-6 v-25 p-64 d-4 v-20 p-57 d-4 v-25 i-80 p-69 d-2 v-15 p
-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80
p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-74 d-15 v-25 p-69 d-12 v-20
p-62 d-12 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65
d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-69
 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-50 p-87 d-6 v-25 p-75 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v
-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-86 d-6 v-25 p-74 d
-6 v-25 i-53 p-71 d-15 v-25 p-67 d-12 v-20 p-59 d-12 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o-36 t-36 i-38 p-
52 d-6 v-25 i-50 p-84 d-6 v-25 p-72 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-25 p-166 d-12 v-2
5 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-50 p-81 d-31 v-25 p-69 d-31 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 i-128 p-208 d-
4 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8 v-25 i-80 p-57 d-6 v-17 p-45
d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-6 v-25 p-64 d-4
 v-20 p-57 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-
6 v-25 i-53 p-72 d-15 v-25 p-69 d-12 v-20 p-60 d-12 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i
-38 p-60 d-6 v-25 i-80 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-60 d-2 v-15 p-60 d
-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-12 v-25 p-64 d-8 v-20 p-57 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167
 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v
-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-1
64 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80 p-65 d-2 v-15 p-65 d
-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-53 p-74 d-6 v-25 p-69 d-4 v-20 p-62 d-4 v-25 i-80 p-65 d-6 v-1
5 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-
53 p-72 d-12 v-25 p-69 d-8 v-20 p-60 d-8 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-
52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-76 d-6 v-25 p-64 d-6 v-25 i-53 p-71 d-12 v-
25 p-67 d-8 v-20 p-59 d-8 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-8
0 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-50 p-81 d-31 v
-25 p-69 d-31 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-80 p-57 d-6 v-17 p-45 d-6
 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-8 v
-20 p-60 d-8 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6
v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-53 p-72 d-12 v-25 p-69 d-8 v-20
p-60 d-8 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v
-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-12 v-25 p-64 d-8 v-20 p-57 d-8 v-25 i-80 p
-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-2 v-15
p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80
 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-72 d-15 v-25 p-69 d-12 v-20
 p-60 d-12 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-15 p-65
 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-80 p-6
9 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80 p-64 d-4 v-17 p-52 d-4
v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-53 p-71 d-15 v-25 p-64
 d-15 v-20 p-59 d-12 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o-36 t-36 i-38 p-52 d-6 v-25 i-50 p-84 d-6 v-25 p
-72 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38
 p-57 d-4 v-25 i-50 p-79 d-6 v-25 p-67 d-6 v-25 i-80 p-69 d-4 v-17 p-57 d-4 v-17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36 i-38 p-57
d-6 v-25 p-45 d-6 v-25 i-50 p-81 d-45 v-25 p-69 d-45 v-25 i-53 p-76 d-4 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45
d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-76 d-12 v-20 p-72 d-15 v-25 p-60 d-12 v-25 o-12 t
-36 i-38 p-57 d-6 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57
 d-6 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-53 p-76 d-8 v-20 p-72 d-12
v-25 p-60 d-8 v-25 i-80 p-72 d-8 v-17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72
d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-12 v-20 p-69 d-12 v-25 p-57 d-12 v-25
 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-80 p-69 d-
2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-
25 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-6 t-36 i-38 p-53 d-6 v-25 i-53 p-77 d-15 v-20 p-74 d-
15 v-25 p-62 d-12 v-25 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-25 i-80 p-65 d-6 v-
15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i
-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-25 i-53 p-76 d-6 v-20 p-72 d-6 v-25 p-60 d-4 v-25 i-80 p-64 d-4 v-17 p-
52 d-4 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-52 d-6 v-25 i-53 p-74 d-12 v-20 p-71 d-12 v-25 p-59 d-8 v-25 i
-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 o-36 t-36 i-38 p-52 d-6 v-25 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-
4 v-25 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-4 v-25 i-53 p-72 d-6 v-20 p-69 d-6 v-25 p-57 d-4 v-2
5 i-80 p-69 d-4 v-17 p-57 d-4 v-17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-25 p-45 d-6 v-25 i-53 p-72 d-6 v-25 p-69
 d-4 v-20 p-60 d-4 v-25 i-80 p-57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-25 o-6 t-36 i-38 p-57 d-6 v-25 i-53 p-7
2 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 o-12 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-6 v-25 p-64 d-4 v-20 p-57 d-4 v-25 i-80 p-69 d-8
v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-18 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-15 v-25 p-69 d-
12 v-20 p-60 d-12 v-25 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 o-24 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-8 v-
17 p-60 d-8 v-17 i-128 p-164 d-12 v-25 p-163 d-12 v-25 o-30 t-36 i-38 p-60 d-6 v-25 i-80 p-72 d-2 v-15 p-72 d-2 v-15 p-60 d-2 v-1
5 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-25 i-53 p-72 d-6 v-25 p-69 d-4 v-20 p-60 d-4 v-25 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-12
8 p-167 d-12 v-25 p-166 d-12 v-25 p-164 d-12 v-25 o-42 t-36 i-38 p-57 d-6 v-25 i-53 p-69 d-6 v-25 p-64 d-4 v-20 p-57 d-4 v-25 i-8
0 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-21 i-53 p-72 d-6 v-20 p-69 d-4 v-20 p-
60 d-4 v-20 i-80 p-65 d-8 v-17 p-53 d-8 v-17 i-128 p-164 d-12 v-21 p-163 d-12 v-21 o-6 t-36 i-38 p-53 d-6 v-21 i-53 p-74 d-15 v-2
0 p-69 d-12 v-20 p-62 d-12 v-20 i-80 p-65 d-2 v-15 p-65 d-2 v-15 p-53 d-2 v-15 p-53 d-2 v-15 o-12 t-36 i-38 p-53 d-6 v-21 i-80 p-
65 d-6 v-15 p-65 d-6 v-15 p-53 d-6 v-15 p-53 d-6 v-15 i-128 p-167 d-12 v-21 p-166 d-12 v-21 p-164 d-12 v-21 o-18 t-36 i-38 p-57 d
-6 v-21 i-80 p-69 d-4 v-17 p-57 d-4 v-17 o-24 t-36 i-38 p-52 d-6 v-21 i-50 p-87 d-6 v-20 p-75 d-6 v-20 i-53 p-72 d-6 v-20 p-69 d-
4 v-20 p-60 d-4 v-20 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-164 d-12 v-21 p-163 d-12 v-21 o-30 t-36 i-38 p-52 d-6 v-21 i-50 p-8
6 d-6 v-20 p-74 d-6 v-20 i-53 p-71 d-15 v-20 p-67 d-12 v-20 p-59 d-12 v-20 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25
o-36 t-36 i-38 p-52 d-6 v-21 i-50 p-84 d-6 v-20 p-72 d-6 v-20 i-80 p-64 d-4 v-17 p-52 d-4 v-17 i-128 p-208 d-4 v-25 p-167 d-12 v-
21 p-166 d-12 v-21 p-164 d-12 v-21 o-42 t-36 i-38 p-57 d-4 v-21 i-50 p-81 d-45 v-20 p-69 d-45 v-20 i-80 p-69 d-4 v-17 p-57 d-4 v-
17 i-128 p-208 d-4 v-25 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-21 p-45 d-6 v-21 i-53 p-72 d-12 v-20 p-69 d-8 v-20 p-60 d-8 v-20 i-80 p-
57 d-6 v-17 p-45 d-6 v-15 p-45 d-6 v-15 i-128 p-163 d-12 v-21 o-6 t-36 i-38 p-57 d-6 v-21 o-12 t-36 i-38 p-57 d-6 v-21 i-53 p-69
d-6 v-20 p-64 d-4 v-20 p-57 d-4 v-20 i-80 p-69 d-8 v-17 p-57 d-8 v-17 i-128 p-167 d-12 v-21 p-166 d-12 v-21 p-164 d-12 v-21 o-18
t-36 i-38 p-57 d-6 v-21 i-53 p-72 d-15 v-20 p-69 d-12 v-20 p-60 d-12 v-20 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-2 v-15 p-57 d-2
 v-15 o-24 t-36 i-38 p-60 d-6 v-21 i-80 p-60 d-8 v-17 i-128 p-164 d-12 v-21 p-163 d-12 v-21 o-30 t-36 i-38 p-60 d-6 v-21 i-80 p-6
0 d-2 v-15 p-60 d-2 v-15 o-36 t-36 i-38 p-57 d-6 v-21 i-53 p-69 d-12 v-20 p-64 d-8 v-20 p-57 d-8 v-20 i-80 p-69 d-8 v-17 p-57 d-8
 v-17 i-128 p-167 d-12 v-21 p-166 d-12 v-21 p-164 d-12 v-21 o-42 t-36 i-38 p-57 d-6 v-21 i-80 p-69 d-2 v-15 p-69 d-2 v-15 p-57 d-
2 v-15 p-57 d-2 v-15 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-17 i-53 p-72 d-6 v-17 p-69 d-4 v-20 p-60 d-4 v-17 i-80 p-65 d-8 v-11 p-53 d
-8 v-11 i-128 p-164 d-12 v-17 p-163 d-12 v-17 o-6 t-36 i-38 p-53 d-6 v-17 i-53 p-72 d-6 v-17 p-69 d-4 v-20 p-60 d-4 v-17 i-80 p-6
5 d-2 v-10 p-65 d-2 v-10 p-53 d-2 v-10 p-53 d-2 v-10 o-12 t-36 i-38 p-53 d-6 v-17 i-53 p-74 d-6 v-17 p-69 d-4 v-20 p-62 d-4 v-17
i-80 p-65 d-6 v-10 p-65 d-6 v-10 p-53 d-6 v-10 p-53 d-6 v-10 i-128 p-167 d-12 v-17 p-166 d-12 v-17 p-164 d-12 v-17 o-18 t-36 i-38
 p-57 d-6 v-17 i-53 p-72 d-12 v-17 p-69 d-8 v-20 p-60 d-8 v-17 i-80 p-69 d-4 v-11 p-57 d-4 v-11 o-24 t-36 i-38 p-52 d-6 v-17 i-80
 p-64 d-4 v-11 p-52 d-4 v-11 i-128 p-164 d-12 v-17 p-163 d-12 v-17 o-30 t-36 i-38 p-52 d-6 v-17 i-53 p-71 d-12 v-17 p-67 d-8 v-20
 p-59 d-8 v-17 i-80 p-64 d-4 v-11 p-52 d-4 v-11 o-36 t-36 i-38 p-52 d-6 v-17 i-80 p-64 d-4 v-11 p-52 d-4 v-11 i-128 p-167 d-12 v-
17 p-166 d-12 v-17 p-164 d-12 v-17 o-42 t-36 i-38 p-57 d-4 v-17 i-80 p-69 d-4 v-11 p-57 d-4 v-11 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v
-17 p-45 d-6 v-17 i-80 p-57 d-6 v-11 p-45 d-6 v-10 p-45 d-6 v-10 i-128 p-163 d-12 v-17 o-6 t-36 i-38 p-57 d-6 v-17 o-12 t-36 i-38
 p-57 d-6 v-17 i-53 p-72 d-12 v-17 p-69 d-8 v-15 p-60 d-8 v-17 i-80 p-69 d-8 v-11 p-57 d-8 v-11 i-128 p-167 d-12 v-17 p-166 d-12
v-17 p-164 d-12 v-17 o-18 t-36 i-38 p-57 d-6 v-17 i-80 p-69 d-2 v-10 p-69 d-2 v-10 p-57 d-2 v-10 p-57 d-2 v-10 o-24 t-36 i-38 p-6
0 d-6 v-17 i-53 p-72 d-12 v-17 p-69 d-8 v-15 p-60 d-8 v-17 i-80 p-72 d-8 v-11 p-60 d-8 v-11 i-128 p-164 d-12 v-17 p-163 d-12 v-17
 o-30 t-36 i-38 p-60 d-6 v-17 i-80 p-72 d-2 v-10 p-72 d-2 v-10 p-60 d-2 v-10 p-60 d-2 v-10 o-36 t-36 i-38 p-57 d-6 v-17 i-53 p-69
 d-12 v-17 p-64 d-8 v-15 p-57 d-8 v-17 i-80 p-69 d-8 v-11 p-57 d-8 v-11 i-128 p-167 d-12 v-17 p-166 d-12 v-17 p-164 d-12 v-17 o-4
2 t-36 i-38 p-57 d-6 v-17 i-80 p-69 d-2 v-10 p-69 d-2 v-10 p-57 d-2 v-10 p-57 d-2 v-10 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-13 i-53 p
-72 d-6 v-17 p-69 d-4 v-15 p-60 d-4 v-17 i-80 p-65 d-8 v-8 p-53 d-8 v-8 i-128 p-164 d-12 v-17 p-163 d-12 v-17 o-6 t-36 i-38 p-53
d-6 v-13 i-53 p-72 d-15 v-17 p-69 d-12 v-15 p-60 d-12 v-17 i-80 p-65 d-2 v-7 p-65 d-2 v-7 p-53 d-2 v-7 p-53 d-2 v-7 o-12 t-36 i-3
8 p-53 d-6 v-13 i-80 p-65 d-6 v-7 p-65 d-6 v-7 p-53 d-6 v-7 p-53 d-6 v-7 i-128 p-167 d-12 v-17 p-166 d-12 v-17 p-164 d-12 v-17 o-
18 t-36 i-38 p-57 d-6 v-13 i-80 p-69 d-4 v-8 p-57 d-4 v-8 o-24 t-36 i-38 p-52 d-6 v-13 i-50 p-87 d-6 v-14 p-75 d-6 v-14 i-53 p-72
 d-6 v-17 p-69 d-4 v-15 p-60 d-4 v-17 i-80 p-64 d-4 v-8 p-52 d-4 v-8 i-128 p-164 d-12 v-17 p-163 d-12 v-17 o-30 t-36 i-38 p-52 d-
6 v-13 i-50 p-86 d-6 v-14 p-74 d-6 v-14 i-53 p-71 d-15 v-17 p-64 d-15 v-15 p-59 d-12 v-17 i-80 p-64 d-4 v-8 p-52 d-4 v-8 i-128 p-
208 d-4 v-16 o-36 t-36 i-38 p-52 d-6 v-13 i-50 p-84 d-6 v-14 p-72 d-6 v-14 i-80 p-64 d-4 v-8 p-52 d-4 v-8 i-128 p-208 d-4 v-16 p-
167 d-12 v-17 p-166 d-12 v-17 p-164 d-12 v-17 o-42 t-36 i-38 p-57 d-4 v-13 i-50 p-81 d-31 v-14 p-69 d-31 v-14 i-80 p-69 d-4 v-8 p
-57 d-4 v-8 i-128 p-208 d-4 v-16 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-13 p-45 d-6 v-13 i-53 p-76 d-4 v-12 p-72 d-6 v-13 p-60 d-4 v-13
 i-80 p-57 d-6 v-8 p-45 d-6 v-7 p-45 d-6 v-7 i-128 p-163 d-12 v-11 o-6 t-36 i-38 p-57 d-6 v-13 i-53 p-76 d-12 v-12 p-72 d-15 v-13
 p-60 d-12 v-13 o-12 t-36 i-38 p-57 d-6 v-13 i-80 p-69 d-8 v-8 p-57 d-8 v-8 i-128 p-167 d-12 v-11 p-166 d-12 v-11 p-164 d-12 v-11
 o-18 t-36 i-38 p-57 d-6 v-13 i-80 p-69 d-2 v-7 p-69 d-2 v-7 p-57 d-2 v-7 p-57 d-2 v-7 o-24 t-36 i-38 p-60 d-6 v-13 i-53 p-76 d-8
 v-12 p-72 d-12 v-13 p-60 d-8 v-13 i-80 p-72 d-8 v-8 p-60 d-8 v-8 i-128 p-164 d-12 v-11 p-163 d-12 v-11 o-30 t-36 i-38 p-60 d-6 v
-13 i-80 p-72 d-2 v-7 p-72 d-2 v-7 p-60 d-2 v-7 p-60 d-2 v-7 o-36 t-36 i-38 p-57 d-6 v-13 i-53 p-72 d-12 v-12 p-69 d-12 v-13 p-57
 d-12 v-13 i-80 p-69 d-8 v-8 p-57 d-8 v-8 i-128 p-167 d-12 v-11 p-166 d-12 v-11 p-164 d-12 v-11 o-42 t-36 i-38 p-57 d-6 v-13 i-80
 p-69 d-2 v-7 p-69 d-2 v-7 p-57 d-2 v-7 p-57 d-2 v-7 b-1 s-9 o-0 t-36 i-38 p-53 d-6 v-11 i-53 p-76 d-6 v-12 p-72 d-6 v-13 p-60 d-
4 v-13 i-80 p-65 d-8 v-7 p-53 d-8 v-7 i-128 p-164 d-12 v-11 p-163 d-12 v-11 o-6 t-36 i-38 p-53 d-6 v-11 i-53 p-77 d-15 v-12 p-74
d-15 v-13 p-62 d-12 v-13 i-80 p-65 d-2 v-6 p-65 d-2 v-6 p-53 d-2 v-6 p-53 d-2 v-6 o-12 t-36 i-38 p-53 d-6 v-11 i-80 p-65 d-6 v-6
p-65 d-6 v-6 p-53 d-6 v-6 p-53 d-6 v-6 i-128 p-167 d-12 v-11 p-166 d-12 v-11 p-164 d-12 v-11 o-18 t-36 i-38 p-57 d-6 v-11 i-80 p-
69 d-4 v-7 p-57 d-4 v-7 o-24 t-36 i-38 p-52 d-6 v-11 i-53 p-76 d-6 v-12 p-72 d-6 v-13 p-60 d-4 v-13 i-80 p-64 d-4 v-7 p-52 d-4 v-
7 i-128 p-164 d-12 v-11 p-163 d-12 v-11 o-30 t-36 i-38 p-52 d-6 v-11 i-50 p-88 d-6 v-10 p-76 d-6 v-10 i-53 p-74 d-12 v-12 p-71 d-
12 v-13 p-59 d-8 v-13 i-80 p-64 d-4 v-7 p-52 d-4 v-7 i-128 p-208 d-4 v-12 o-36 t-36 i-38 p-52 d-6 v-11 i-50 p-91 d-6 v-10 p-79 d-
6 v-10 i-80 p-64 d-4 v-7 p-52 d-4 v-7 i-128 p-208 d-4 v-12 p-167 d-12 v-11 p-166 d-12 v-11 p-164 d-12 v-11 o-42 t-36 i-38 p-57 d-
4 v-11 i-50 p-93 d-31 v-10 p-81 d-31 v-10 i-53 p-72 d-6 v-12 p-69 d-6 v-13 p-57 d-4 v-13 i-80 p-69 d-4 v-7 p-57 d-4 v-7 i-128 p-2
08 d-4 v-12 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-11 p-45 d-6 v-11 i-53 p-72 d-6 v-10 p-69 d-4 v-9 p-60 d-4 v-10 i-80 p-57 d-6 v-7 p-4
5 d-6 v-6 p-45 d-6 v-6 i-128 p-163 d-12 v-8 o-6 t-36 i-38 p-57 d-6 v-11 i-53 p-72 d-6 v-10 p-69 d-4 v-9 p-60 d-4 v-10 o-12 t-36 i
-38 p-57 d-6 v-11 i-53 p-69 d-6 v-10 p-64 d-4 v-9 p-57 d-4 v-10 i-80 p-69 d-8 v-7 p-57 d-8 v-7 i-128 p-167 d-12 v-8 p-166 d-12 v-
8 p-164 d-12 v-8 o-18 t-36 i-38 p-57 d-6 v-11 i-53 p-72 d-15 v-10 p-69 d-12 v-9 p-60 d-12 v-10 i-80 p-69 d-2 v-6 p-69 d-2 v-6 p-5
7 d-2 v-6 p-57 d-2 v-6 o-24 t-36 i-38 p-60 d-6 v-11 i-80 p-72 d-8 v-7 p-60 d-8 v-7 i-128 p-164 d-12 v-8 p-163 d-12 v-8 o-30 t-36
i-38 p-60 d-6 v-11 i-80 p-72 d-2 v-6 p-72 d-2 v-6 p-60 d-2 v-6 p-60 d-2 v-6 o-36 t-36 i-38 p-57 d-6 v-11 i-53 p-72 d-6 v-10 p-69
d-4 v-9 p-60 d-4 v-10 i-80 p-69 d-8 v-7 p-57 d-8 v-7 i-128 p-167 d-12 v-8 p-166 d-12 v-8 p-164 d-12 v-8 o-42 t-36 i-38 p-57 d-6 v
-11 i-53 p-69 d-6 v-10 p-64 d-4 v-9 p-57 d-4 v-10 i-80 p-69 d-2 v-6 p-69 d-2 v-6 p-57 d-2 v-6 p-57 d-2 v-6 b-1 s-9 o-0 t-36 i-38
p-53 d-6 v-7 i-53 p-72 d-6 v-10 p-69 d-4 v-9 p-60 d-4 v-10 i-80 p-65 d-8 v-4 p-53 d-8 v-4 i-128 p-164 d-12 v-8 p-163 d-12 v-8 o-6
 t-36 i-38 p-53 d-6 v-7 i-53 p-74 d-15 v-10 p-69 d-12 v-9 p-62 d-12 v-10 i-80 p-65 d-2 v-4 p-65 d-2 v-4 p-53 d-2 v-4 p-53 d-2 v-4
 o-12 t-36 i-38 p-53 d-6 v-7 i-80 p-65 d-6 v-4 p-65 d-6 v-4 p-53 d-6 v-4 p-53 d-6 v-4 i-128 p-167 d-12 v-8 p-166 d-12 v-8 p-164 d
-12 v-8 o-18 t-36 i-38 p-57 d-6 v-7 i-80 p-69 d-4 v-4 p-57 d-4 v-4 o-24 t-36 i-38 p-52 d-6 v-7 i-50 p-87 d-6 v-8 p-75 d-6 v-8 i-5
3 p-72 d-6 v-10 p-69 d-4 v-9 p-60 d-4 v-10 i-80 p-64 d-4 v-4 p-52 d-4 v-4 i-128 p-164 d-12 v-8 p-163 d-12 v-8 o-30 t-36 i-38 p-52
 d-6 v-7 i-50 p-86 d-6 v-8 p-74 d-6 v-8 i-53 p-71 d-15 v-10 p-67 d-12 v-9 p-59 d-12 v-10 i-80 p-64 d-4 v-4 p-52 d-4 v-4 i-128 p-2
08 d-4 v-7 o-36 t-36 i-38 p-52 d-6 v-7 i-50 p-84 d-6 v-8 p-72 d-6 v-8 i-80 p-64 d-4 v-4 p-52 d-4 v-4 i-128 p-208 d-4 v-7 p-167 d-
12 v-8 p-166 d-12 v-8 p-164 d-12 v-8 o-42 t-36 i-38 p-57 d-4 v-7 i-50 p-81 d-38 v-8 p-69 d-38 v-8 i-80 p-69 d-4 v-4 p-57 d-4 v-4
i-128 p-208 d-4 v-7 b-1 s-9 o-0 t-36 i-38 p-57 d-6 v-7 p-45 d-6 v-7 i-53 p-72 d-12 v-7 p-69 d-8 v-6 p-60 d-8 v-7 i-80 p-57 d-6 v-
4 p-45 d-6 v-4 p-45 d-6 v-4 i-128 p-163 d-12 v-5 o-6 t-36 i-38 p-57 d-6 v-7 o-12 t-36 i-38 p-57 d-6 v-7 i-53 p-69 d-6 v-7 p-64 d-
4 v-6 p-57 d-4 v-7 i-80 p-69 d-8 v-4 p-57 d-8 v-4 i-128 p-167 d-12 v-5 p-166 d-12 v-5 p-164 d-12 v-5 o-18 t-36 i-38 p-57 d-6 v-7
i-53 p-72 d-15 v-7 p-69 d-12 v-6 p-60 d-12 v-7 i-80 p-69 d-2 v-4 p-69 d-2 v-4 p-57 d-2 v-4 p-57 d-2 v-4 o-24 t-36 i-38 p-60 d-6 v
-7 i-80 p-60 d-8 v-4 i-128 p-164 d-12 v-5 p-163 d-12 v-5 o-30 t-36 i-38 p-60 d-6 v-7 i-80 p-60 d-2 v-4 p-60 d-2 v-4 o-36 t-36 i-3
8 p-57 d-6 v-7 i-53 p-69 d-12 v-7 p-64 d-8 v-6 p-57 d-8 v-7 i-80 p-69 d-8 v-4 p-57 d-8 v-4 i-128 p-167 d-12 v-5 p-166 d-12 v-5 p-
164 d-12 v-5 o-42 t-36 i-38 p-57 d-6 v-7 i-80 p-69 d-2 v-4 p-69 d-2 v-4 p-57 d-2 v-4 p-57 d-2 v-4 b-1 s-9 o-0 t-36 i-38 p-53 d-6
v-7 i-53 p-72 d-6 v-7 p-69 d-4 v-6 p-60 d-4 v-7 i-80 p-65 d-8 v-4 p-53 d-8 v-4 i-128 p-164 d-12 v-5 p-163 d-12 v-5 o-6 t-36 i-38
p-53 d-6 v-7 i-53 p-72 d-6 v-7 p-69 d-4 v-6 p-60 d-4 v-7 i-80 p-65 d-2 v-4 p-65 d-2 v-4 p-53 d-2 v-4 p-53 d-2 v-4 o-12 t-36 i-38
p-53 d-6 v-7 i-53 p-74 d-6 v-7 p-69 d-4 v-6 p-62 d-4 v-7 i-80 p-65 d-6 v-4 p-65 d-6 v-4 p-53 d-6 v-4 p-53 d-6 v-4 i-128 p-167 d-1
2 v-5 p-166 d-12 v-5 p-164 d-12 v-5 o-18 t-36 i-38 p-57 d-6 v-7 i-53 p-72 d-12 v-7 p-69 d-8 v-6 p-60 d-8 v-7 i-80 p-69 d-4 v-4 p-
57 d-4 v-4 o-24 t-36 i-38 p-52 d-6 v-7 i-80 p-64 d-4 v-4 p-52 d-4 v-4 i-128 p-164 d-12 v-5 p-163 d-12 v-5 o-30 t-36 i-38 p-52 d-6
 v-7 i-53 p-71 d-12 v-7 p-67 d-8 v-6 p-59 d-8 v-7 i-80 p-64 d-4 v-4 p-52 d-4 v-4 o-36 t-36 i-38 p-52 d-6 v-7 i-80 p-64 d-4 v-4 p-
52 d-4 v-4 i-128 p-167 d-12 v-5 p-166 d-12 v-5 p-164 d-12 v-5 o-42 t-36 i-38 p-57 d-4 v-7 i-80 p-69 d-4 v-4 p-57 d-4 v-4 b-1'}
Tokenized text: {'input_ids': [57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 1
10, 33, 6, 8, 64, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31,
 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 4
7, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39,
 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 5
8, 6, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31,
 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19,
 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41,
 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 4
3, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39
, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8
, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110,
 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19
, 8, 70, 41, 110, 58, 6, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58
, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46,
 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3,
 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6,
31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110
, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68
, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38,
19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58
, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6
, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 1
79, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17,
 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179,
 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38,
 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 2
7, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 179, 39, 79, 27,
33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8,
179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 5
8, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 4
1, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46,
 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 58, 1
9, 8, 154, 123, 326, 8, 47, 326, 8, 39, 326, 8, 179, 58, 19, 27, 3, 43, 19, 8, 64, 41, 110, 52, 6, 8, 179, 52, 6, 27, 3, 139, 19,
 8, 54, 19, 8, 66, 41, 110, 58, 19, 8, 179, 58, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 52, 6, 8, 179, 52, 6, 27, 63, 41, 110,
 58, 6, 8, 179, 58, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 52, 6, 8, 179, 52, 6, 27, 56, 57, 60, 41, 110, 46, 19, 8, 179,
46, 19, 27, 3, 43, 19, 8, 64, 41, 110, 30, 6, 8, 179, 30, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 46, 19, 8, 179, 46, 19, 2
7, 62, 41, 168, 148, 72, 8, 47, 72, 8, 154, 80, 102, 8, 47, 102, 8, 39, 102, 8, 3, 43, 19, 8, 68, 41, 110, 30, 6, 8, 179, 30, 6,
27, 117, 41, 168, 165, 6, 8, 81, 6, 8, 63, 41, 110, 46, 6, 8, 179, 46, 6, 27, 3, 139, 19, 8, 54, 19, 8, 128, 41, 168, 109, 72, 8,
 39, 72, 8, 67, 41, 110, 30, 6, 8, 179, 30, 6, 27, 56, 57, 60, 41, 110, 33, 19, 8, 168, 165, 93, 8, 81, 93, 8, 179, 33, 19, 27, 3
, 43, 19, 8, 64, 41, 110, 33, 6, 8, 179, 33, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 33, 6, 8, 168, 148, 6, 8, 47, 6, 8, 17
9, 33, 6, 27, 62, 41, 110, 33, 6, 8, 168, 109, 102, 8, 39, 102, 8, 179, 33, 6, 27, 3, 43, 19, 8, 68, 41, 110, 33, 6, 8, 179, 33,
6, 27, 63, 41, 110, 33, 19, 8, 154, 106, 19, 8, 80, 19, 8, 47, 19, 8, 179, 33, 19, 27, 3, 139, 19, 8, 54, 19, 8, 56, 57, 60, 41,
110, 50, 19, 8, 154, 123, 102, 8, 71, 102, 8, 39, 102, 8, 179, 50, 19, 27, 3, 43, 19, 8, 64, 41, 110, 35, 6, 8, 179, 35, 6, 27, 3
, 139, 19, 8, 54, 19, 8, 66, 41, 110, 50, 19, 8, 179, 50, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 35, 6, 8, 168, 39, 17, 8, 33
, 17, 8, 179, 35, 6, 27, 254, 41, 168, 47, 17, 8, 21, 17, 8, 63, 41, 110, 50, 6, 8, 168, 71, 17, 8, 35, 17, 8, 179, 50, 6, 27, 3,
 139, 19, 8, 54, 19, 8, 256, 41, 168, 257, 17, 8, 196, 17, 8, 67, 41, 110, 35, 6, 8, 179, 35, 6, 27, 281, 41, 168, 71, 17, 8, 35,
 17, 8, 238, 41, 168, 47, 176, 8, 21, 176, 8, 56, 57, 60, 41, 110, 58, 19, 8, 154, 123, 102, 8, 47, 102, 8, 39, 102, 8, 179, 58,
19, 27, 3, 43, 19, 8, 64, 41, 110, 52, 6, 8, 179, 52, 6, 27, 365, 80, 297, 8, 47, 297, 8, 39, 297, 8, 30, 297, 8, 3, 139, 19, 8,
54, 19, 8, 66, 41, 110, 58, 19, 8, 179, 58, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 52, 6, 8, 179, 52, 6, 27, 117, 41, 168, 25
7, 4, 8, 196, 4, 8, 63, 41, 110, 58, 6, 8, 168, 71, 4, 8, 35, 4, 8, 179, 58, 6, 27, 3, 139, 19, 8, 54, 19, 8, 128, 41, 168, 47, 8
5, 8, 21, 85, 8, 67, 41, 110, 52, 6, 8, 179, 52, 6, 27, 56, 57, 60, 41, 110, 46, 19, 8, 168, 80, 82, 8, 30, 82, 8, 154, 80, 102,
8, 47, 102, 8, 39, 102, 8, 179, 46, 19, 27, 3, 43, 19, 8, 64, 41, 110, 30, 6, 8, 179, 30, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41
, 110, 46, 19, 8, 179, 46, 19, 27, 62, 41, 168, 106, 6, 8, 34, 6, 8, 3, 43, 19, 8, 68, 41, 110, 30, 6, 8, 168, 109, 93, 8, 39, 93
, 8, 179, 30, 6, 27, 63, 41, 110, 46, 6, 8, 179, 46, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 30, 6, 8, 179, 30, 6, 27, 56,
57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33,
6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33,
 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21,
6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 39, 19, 8, 33, 79, 8, 179, 39, 79, 27, 33, 79,
 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 154, 47
, 6, 8, 21, 17, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 47, 93, 8, 21, 19, 8, 179, 52, 5, 31, 5
2, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110
, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19,
 8, 68, 41, 110, 46, 6, 8, 154, 81, 93, 8, 49, 19, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17
, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 154, 47, 6, 8,
21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 47, 93, 8, 21, 19, 8, 64, 41, 110, 33,
 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41,
 110, 21, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47,
5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 39, 19, 8, 33, 19, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41,
 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 52
, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 71, 93, 8, 35, 19, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5
, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 2
7, 33, 17, 27, 62, 41, 110, 46, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8,
 154, 81, 19, 8, 49, 79, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41
, 110, 33, 17, 8, 154, 39, 6, 8, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 154, 47, 6, 8,
21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 47, 6, 8, 21, 17, 8, 64, 41, 110, 33, 6, 8, 154,
39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 47, 93, 8, 21, 19, 8, 179, 39, 5, 31,
 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 21, 5, 31, 6
3, 41, 110, 33, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 154, 39, 6, 8,
33, 17, 8, 179, 39, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38
, 19, 8, 70, 41, 110, 58, 6, 8, 154, 71, 93, 8, 35, 19, 8, 179, 52, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 58,
6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 30
, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 154, 81, 93, 8, 49, 19, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 4
6, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33,
 6, 8, 76, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 33, 6, 27, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33, 6, 8
, 154, 39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 47, 93, 8, 21, 19, 8, 179, 39,
 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 21, 5
, 31, 63, 41, 110, 33, 6, 8, 154, 39, 19, 8, 33, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39
, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 1
10, 58, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 52, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 154, 71, 6, 8, 35, 17, 8, 179, 52, 6, 3
1, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8,
 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 154, 81, 19, 8, 49, 79, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41
, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41,
110, 33, 6, 8, 76, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 3
3, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 64, 41, 110, 33, 6, 8, 154, 47, 19, 12, 39, 19, 8, 33, 79, 8, 179, 39, 79, 27, 33,
 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 154, 80, 19
, 12, 47, 19, 8, 21, 79, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 3
1, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 47, 17, 12, 39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110
, 33, 6, 8, 154, 80, 19, 12, 47, 19, 8, 21, 79, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8
, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 71, 82, 12, 39, 82, 8, 33, 82, 8, 179, 52, 5, 31, 52, 5,
 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33,
 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179,
 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 2
7, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 3
1, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 64, 41, 110, 33, 6, 8, 154, 47, 19, 12, 39, 19, 8,
33, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62,
 41, 110, 21, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 154,
80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 47, 17, 12, 39, 6,
8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 154, 80, 19, 12, 47, 19, 8, 21, 79, 8, 179, 39, 5
, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58,
 6, 8, 154, 123, 19, 12, 71, 19, 8, 35, 79, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6
, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 39, 17, 27
, 33, 17, 27, 62, 41, 110, 46, 6, 8, 154, 71, 82, 12, 81, 82, 8, 49, 121, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 1
10, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17,
 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 33, 6, 27, 7
6, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 64, 41, 110, 33, 6, 8, 154, 47, 19, 12, 39,
19, 8, 33, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6
, 8, 154, 80, 17, 12, 47, 6, 8, 21, 17, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 154, 80, 17, 12, 47,
 6, 8, 21, 17, 8, 179, 47, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 47, 6, 12, 39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79,
 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 154, 80, 19, 12, 47, 19, 8, 21, 79, 8, 179, 39, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110,
58, 6, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 71, 82, 12, 39, 82, 8, 33, 82, 8, 179, 52, 5, 31
, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27,
62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110
, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110,
33, 6, 8, 76, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 47, 6, 8, 21,
17, 8, 64, 41, 110, 33, 6, 8, 154, 39, 19, 8, 33, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 3
9, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21
, 6, 8, 179, 47, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67
, 41, 110, 33, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 39, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58, 79
, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 71, 19, 8, 35, 79, 8, 179, 52, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52,
6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6,
 8, 154, 81, 82, 8, 49, 121, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 63
, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60,
41, 110, 58, 19, 8, 154, 123, 326, 8, 47, 326, 8, 39, 326, 8, 179, 58, 19, 27, 3, 43, 19, 8, 64, 41, 110, 52, 6, 8, 179, 52, 6, 2
7, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 58, 19, 8, 179, 58, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 52, 6, 8, 179, 52, 6, 27
, 63, 41, 110, 58, 6, 8, 179, 58, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 52, 6, 8, 179, 52, 6, 27, 56, 57, 60, 41, 110, 46
, 19, 8, 179, 46, 19, 27, 3, 43, 19, 8, 64, 41, 110, 30, 6, 8, 179, 30, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 46, 19, 8,
179, 46, 19, 27, 62, 41, 154, 80, 102, 8, 71, 102, 8, 39, 102, 8, 3, 43, 19, 8, 267, 41, 168, 257, 17, 8, 196, 17, 8, 274, 41, 16
8, 71, 17, 8, 35, 17, 8, 68, 41, 110, 30, 6, 8, 179, 30, 6, 27, 117, 41, 168, 47, 6, 8, 21, 6, 8, 63, 41, 110, 46, 6, 8, 168, 71,
 82, 8, 35, 82, 8, 179, 46, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 30, 6, 8, 179, 30, 6, 27, 56, 57, 60, 41, 110, 33, 19,
8, 179, 33, 19, 27, 3, 43, 19, 8, 64, 41, 110, 33, 6, 8, 179, 33, 6, 27, 3, 139, 19, 8, 54, 19, 8, 283, 41, 168, 257, 4, 8, 196,
4, 8, 66, 41, 110, 33, 6, 8, 168, 47, 102, 8, 21, 102, 8, 179, 33, 6, 27, 62, 41, 110, 33, 6, 8, 179, 33, 6, 27, 3, 43, 19, 8, 68
, 41, 110, 33, 6, 8, 179, 33, 6, 27, 63, 41, 110, 33, 19, 8, 154, 106, 19, 8, 80, 19, 8, 47, 19, 8, 179, 33, 19, 27, 3, 139, 19,
8, 54, 19, 8, 56, 57, 60, 41, 110, 50, 19, 8, 154, 123, 102, 8, 71, 102, 8, 39, 102, 8, 179, 50, 19, 27, 3, 43, 19, 8, 64, 41, 11
0, 35, 6, 8, 168, 47, 6, 8, 21, 6, 8, 179, 35, 6, 27, 3, 139, 19, 8, 54, 19, 8, 278, 41, 168, 71, 6, 8, 35, 6, 8, 66, 41, 110, 50
, 19, 8, 179, 50, 19, 27, 114, 41, 168, 257, 6, 8, 196, 6, 8, 62, 41, 168, 47, 82, 8, 21, 82, 8, 3, 43, 19, 8, 68, 41, 110, 35, 6
, 8, 179, 35, 6, 27, 63, 41, 110, 50, 6, 8, 179, 50, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 35, 6, 8, 179, 35, 6, 27, 56,
57, 60, 41, 110, 58, 19, 8, 154, 123, 102, 8, 47, 102, 8, 39, 102, 8, 179, 58, 19, 27, 3, 43, 19, 8, 64, 41, 110, 52, 6, 8, 179,
52, 6, 27, 365, 80, 378, 20, 47, 378, 20, 39, 378, 20, 30, 378, 20, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 58, 19, 8, 179, 58, 19
, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 52, 6, 8, 179, 52, 6, 27, 63, 41, 110, 58, 6, 8, 179, 58, 6, 27, 3, 139, 19, 8, 54, 19,
8, 67, 41, 110, 52, 6, 8, 179, 52, 6, 27, 56, 57, 60, 41, 110, 46, 19, 8, 168, 106, 6, 8, 34, 6, 8, 154, 80, 102, 8, 47, 102, 8,
39, 102, 8, 179, 46, 19, 27, 3, 43, 19, 8, 70, 41, 168, 80, 19, 8, 30, 19, 8, 64, 41, 110, 30, 6, 8, 179, 30, 6, 27, 3, 139, 19,
8, 54, 19, 8, 66, 41, 110, 46, 19, 8, 168, 80, 6, 8, 30, 6, 8, 179, 46, 19, 27, 62, 41, 168, 71, 6, 8, 35, 6, 8, 3, 43, 19, 8, 13
0, 41, 168, 47, 6, 8, 21, 6, 8, 68, 41, 110, 30, 6, 8, 179, 30, 6, 27, 288, 41, 168, 39, 16, 8, 33, 16, 8, 63, 41, 110, 46, 6, 8,
 168, 47, 19, 8, 21, 19, 8, 179, 46, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 30, 6, 8, 179, 30, 6, 27, 56, 57, 60, 41, 110,
 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33, 6, 8, 179, 39, 7
9, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 1
79, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33
, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57
, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31,
58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39,
17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46,
 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 5
6, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 3
3, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 4
1, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5,
31, 63, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31
, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 179, 52, 5, 31, 52,
 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110,
33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 1
79, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17
, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6
, 8, 64, 41, 110, 33, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39,
 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 154, 47, 19, 8, 21, 79, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19
, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 39, 19, 8, 33, 79, 8, 17
9, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 56, 57, 60, 41,
110, 58, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 47, 93, 8, 21, 19
, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3,
38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 154, 47, 6, 8, 21, 17, 8, 179, 30, 17, 27,
46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 154, 81, 93, 8, 49, 19, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 1
79, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76,
 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 80, 9
3, 12, 47, 93, 8, 21, 19, 8, 64, 41, 110, 33, 6, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 5,
 31, 39, 5, 31, 33, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 154, 80, 19, 12, 47, 19, 8, 21, 79, 8, 179, 47, 79, 27, 21, 79, 27,
3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179, 47, 5, 31, 47, 5, 31, 21, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 47, 19, 12, 39,
 19, 8, 33, 19, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 39, 5, 31, 33, 5, 31, 33, 5,
 31, 56, 57, 60, 41, 110, 58, 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110,
58, 6, 8, 154, 123, 93, 12, 71, 93, 8, 35, 19, 8, 179, 52, 5, 31, 52, 5, 31, 58, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52
, 6, 31, 52, 6, 31, 58, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8
, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 110, 46, 6, 8, 154, 71, 19, 12, 81, 19,
 8, 49, 79, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17
, 8, 154, 47, 6, 12, 39, 6, 8, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8, 154, 80, 6, 12, 4
7, 6, 8, 21, 17, 8, 179, 33, 6, 27, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 64, 41,
110, 33, 6, 8, 154, 47, 6, 12, 39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 80, 93
, 12, 47, 93, 8, 21, 19, 8, 179, 39, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41,
110, 21, 6, 8, 179, 47, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 39, 79, 27, 33, 79, 27
, 3, 38, 19, 8, 67, 41, 110, 33, 6, 8, 154, 47, 6, 12, 39, 6, 8, 33, 17, 8, 179, 39, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6
, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 52, 79, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 123, 93, 12, 71,
 93, 8, 35, 19, 8, 179, 52, 5, 31, 58, 5, 31, 64, 41, 110, 58, 6, 8, 179, 52, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6,
 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38,
19, 8, 68, 41, 110, 46, 6, 8, 154, 71, 93, 12, 81, 93, 8, 49, 19, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30,
 17, 27, 46, 17, 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 33, 6, 8, 76, 6, 8,
154, 80, 19, 12, 47, 19, 8, 21, 79, 8, 179, 33, 6, 27, 76, 6, 31, 3, 43, 19, 8, 70, 41, 110, 33, 6, 8, 64, 41, 110, 33, 6, 8, 154
, 47, 6, 12, 39, 6, 8, 33, 17, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 80, 93, 12, 47, 93, 8, 2
1, 19, 8, 179, 39, 5, 31, 33, 5, 31, 62, 41, 110, 21, 6, 8, 179, 47, 79, 27, 21, 79, 27, 3, 38, 19, 8, 68, 41, 110, 21, 6, 8, 179
, 47, 5, 31, 21, 5, 31, 63, 41, 110, 33, 6, 8, 154, 47, 19, 12, 39, 19, 8, 33, 79, 8, 179, 39, 79, 27, 33, 79, 27, 3, 38, 19, 8,
67, 41, 110, 33, 6, 8, 179, 39, 5, 31, 33, 5, 31, 56, 57, 60, 41, 110, 58, 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 52, 79
, 27, 58, 79, 27, 3, 38, 19, 8, 70, 41, 110, 58, 6, 8, 154, 80, 6, 12, 47, 6, 8, 21, 17, 8, 179, 52, 5, 31, 58, 5, 31, 64, 41, 11
0, 58, 6, 8, 154, 123, 6, 12, 71, 6, 8, 35, 17, 8, 179, 52, 6, 31, 58, 6, 31, 3, 38, 19, 8, 66, 41, 110, 33, 6, 8, 154, 80, 19, 1
2, 47, 19, 8, 21, 79, 8, 179, 39, 17, 27, 33, 17, 27, 62, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17, 27, 3, 38, 19, 8, 68, 41, 1
10, 46, 6, 8, 154, 71, 19, 12, 81, 19, 8, 49, 79, 8, 179, 30, 17, 27, 46, 17, 27, 63, 41, 110, 46, 6, 8, 179, 30, 17, 27, 46, 17,
 27, 3, 38, 19, 8, 67, 41, 110, 33, 17, 8, 179, 39, 17, 27, 33, 17, 27, 56, 57, 60, 41, 110, 58, 19, 8, 154, 123, 326, 8, 47, 326
, 8, 39, 326, 8, 179, 58, 19, 27, 3, 43, 19, 8, 64, 41, 110, 52, 6, 8, 179, 52, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 58,
 19, 8, 179, 58, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 52, 6, 8, 179, 52, 6, 27, 63, 41, 110, 58, 6, 8, 179, 58, 6, 27, 3, 1
39, 19, 8, 54, 19, 8, 67, 41, 110, 52, 6, 8, 179, 52, 6, 27, 56, 57, 60, 41, 110, 46, 19, 8, 179, 46, 19, 27, 3, 43, 19, 8, 64, 4
1, 110, 30, 6, 8, 179, 30, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 46, 19, 8, 179, 46, 19, 27, 62, 41, 168, 148, 72, 8, 47,
 72, 8, 154, 80, 102, 8, 47, 102, 8, 39, 102, 8, 3, 43, 19, 8, 68, 41, 110, 30, 6, 8, 179, 30, 6, 27, 117, 41, 168, 165, 6, 8, 81
, 6, 8, 63, 41, 110, 46, 6, 8, 179, 46, 6, 27, 3, 139, 19, 8, 54, 19, 8, 128, 41, 168, 109, 72, 8, 39, 72, 8, 67, 41, 110, 30, 6,
 8, 179, 30, 6, 27, 56, 57, 60, 41, 110, 33, 19, 8, 168, 165, 93, 8, 81, 93, 8, 179, 33, 19, 27, 3, 43, 19, 8, 64, 41, 110, 33, 6
, 8, 179, 33, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 33, 6, 8, 168, 148, 6, 8, 47, 6, 8, 179, 33, 6, 27, 62, 41, 110, 33,
6, 8, 168, 109, 102, 8, 39, 102, 8, 179, 33, 6, 27, 3, 43, 19, 8, 68, 41, 110, 33, 6, 8, 179, 33, 6, 27, 63, 41, 110, 33, 19, 8,
154, 106, 19, 8, 80, 19, 8, 47, 19, 8, 179, 33, 19, 27, 3, 139, 19, 8, 54, 19, 8, 56, 57, 60, 41, 110, 50, 19, 8, 154, 123, 102,
8, 71, 102, 8, 39, 102, 8, 179, 50, 19, 27, 3, 43, 19, 8, 64, 41, 110, 35, 6, 8, 179, 35, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41
, 110, 50, 19, 8, 179, 50, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 35, 6, 8, 168, 39, 17, 8, 33, 17, 8, 179, 35, 6, 27, 254, 4
1, 168, 47, 17, 8, 21, 17, 8, 63, 41, 110, 50, 6, 8, 168, 71, 17, 8, 35, 17, 8, 179, 50, 6, 27, 3, 139, 19, 8, 54, 19, 8, 256, 41
, 168, 257, 17, 8, 196, 17, 8, 67, 41, 110, 35, 6, 8, 179, 35, 6, 27, 281, 41, 168, 71, 17, 8, 35, 17, 8, 238, 41, 168, 47, 176,
8, 21, 176, 8, 56, 57, 60, 41, 110, 58, 19, 8, 154, 123, 102, 8, 47, 102, 8, 39, 102, 8, 179, 58, 19, 27, 3, 43, 19, 8, 64, 41, 1
10, 52, 6, 8, 179, 52, 6, 27, 365, 80, 297, 8, 47, 297, 8, 39, 297, 8, 30, 297, 8, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 58, 19,
 8, 179, 58, 19, 27, 62, 41, 3, 43, 19, 8, 68, 41, 110, 52, 6, 8, 179, 52, 6, 27, 117, 41, 168, 257, 4, 8, 196, 4, 8, 63, 41, 110
, 58, 6, 8, 168, 71, 4, 8, 35, 4, 8, 179, 58, 6, 27, 3, 139, 19, 8, 54, 19, 8, 128, 41, 168, 47, 85, 8, 21, 85, 8, 67, 41, 110, 5
2, 6, 8, 179, 52, 6, 27, 56, 57, 60, 41, 110, 46, 19, 8, 168, 80, 82, 8, 30, 82, 8, 154, 80, 102, 8, 47, 102, 8, 39, 102, 8, 179,
 46, 19, 27, 3, 43, 19, 8, 64, 41, 110, 30, 6, 8, 179, 30, 6, 27, 3, 139, 19, 8, 54, 19, 8, 66, 41, 110, 46, 19, 8, 179, 46, 19,
27, 62, 41, 168, 106, 6, 8, 34, 6, 8, 3, 43, 19, 8, 68, 41, 110, 30, 6, 8, 168, 109, 380, 8, 39, 380, 8, 179, 30, 6, 27, 63, 41,
110, 46, 6, 8, 179, 46, 6, 27, 3, 139, 19, 8, 54, 19, 8, 67, 41, 110, 30, 6, 8, 179, 30, 6, 27, 56, 57, 60, 41, 37, 39, 102, 8, 3
0, 102, 8, 33, 102, 8, 46, 102, 8, 154, 195, 17, 8, 148, 17, 8, 106, 17, 8, 3, 11, 4, 8, 43, 19, 8, 136, 41, 3, 11, 4, 8, 70, 41,
 154, 109, 17, 8, 80, 17, 8, 3, 11, 4, 8, 113, 41, 3, 11, 4, 8, 64, 41, 154, 109, 5, 8, 80, 5, 8, 3, 11, 4, 8, 43, 19, 8, 134, 41
, 154, 109, 5, 8, 80, 5, 8, 3, 11, 4, 8, 66, 41, 3, 11, 4, 8, 114, 41, 3, 11, 4, 8, 62, 41, 3, 11, 4, 8, 43, 19, 8, 130, 41, 3, 1
1, 4, 8, 68, 41, 3, 11, 4, 8, 117, 41, 3, 11, 4, 8, 63, 41, 3, 11, 4, 8, 43, 19, 8, 128, 41, 3, 11, 4, 8, 67, 41, 3, 11, 4, 8, 11
6, 41, 3, 11, 4, 8, 56, 57, 60, 41, 37, 47, 102, 8, 34, 102, 8, 21, 102, 8, 26, 102, 8, 154, 148, 17, 8, 106, 17, 8, 3, 11, 4, 8,
 43, 19, 8, 136, 41, 3, 11, 4, 8, 70, 41, 154, 109, 17, 8, 80, 17, 8, 3, 11, 4, 8, 113, 41, 3, 11, 4, 8, 64, 41, 154, 109, 5, 8,
80, 5, 8, 3, 11, 4, 8, 43, 19, 8, 134, 41, 154, 109, 5, 8, 80, 5, 8, 3, 11, 4, 8, 66, 41, 3, 11, 4, 8, 114, 41, 3, 11, 4, 8, 62,
41, 154, 81, 72, 8, 34, 72, 8, 3, 11, 4, 8, 43, 19, 8, 130, 41, 3, 11, 4, 8, 68, 41, 3, 11, 4, 8, 117, 41, 154, 81, 4, 8, 34, 4,
8, 3, 11, 4, 8, 63, 41, 154, 47, 6, 8, 39, 6, 8, 3, 11, 4, 8, 43, 19, 8, 128, 41, 3, 11, 4, 8, 67, 41, 3, 11, 4, 8, 116, 41, 3, 1
1, 4, 8, 56, 57, 60, 41, 37, 39, 102, 8, 30, 102, 8, 33, 102, 8, 46, 102, 8, 168, 21, 102, 8, 154, 148, 17, 8, 106, 17, 8, 3, 11,
 4, 8, 43, 19, 8, 136, 41, 3, 11, 4, 8, 70, 41, 154, 109, 17, 8, 80, 17, 8, 3, 11, 4, 8, 113, 41, 3, 11, 4, 8, 64, 41, 154, 109,
5, 8, 80, 5, 8, 3, 11, 4, 8, 43, 19, 8, 134, 41, 154, 109, 5, 8]}
Creating model...
Creating xLSTMLMModel...
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
Creating extension directory /home/e20037/.cache/torch_extensions/py311_cu124/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GR
C0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/e20037/.cache/torch_extensions/py311_cu124/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d
0FCV0FC0d0/build.ninja...
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LI
ST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
[1/8] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -cc
bin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAf
NG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DP
YBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/minicon
da/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packag
es/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python
3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D
__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89
 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --ex
tra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=fl
oat -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLS
TM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECU
RRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_C
ONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BF
LOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/util/cu
da_error.cu -o cuda_error.cuda.o
ptxas info    : 0 bytes gmem
[2/8] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d
-ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSb
DAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\"
-DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isyst
em /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/mini
conda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-pac
kages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/pyt
hon3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__
 -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm
_89 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 -
-extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B
=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -D
SLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_R
ECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HAL
F_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO
_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cuda
/slstm_forward.cu -o slstm_forward.cuda.o
ptxas info    : 0 bytes gmem
[3/8] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda
.o.d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbD
GbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdc
pp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -
isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037
/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/sit
e-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/includ
e/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSI
ONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,co
de=sm_89 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas
-O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DT
YPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat
16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADI
ENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_N
O_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CU
DA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src
/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKer
nelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_89'
ptxas info    : Function properties for _ZN54_GLOBAL__N__8a3facab_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKerne
lEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, 400 bytes cmem[0]
[4/8] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.
d -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbD
SbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\
" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isy
stem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/mi
niconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-p
ackages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/p
ython3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS
__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=
sm_89 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3
 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE
_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16
-DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT
_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_H
ALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_
NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cu
da/slstm_pointwise.cu -o slstm_pointwise.cuda.o
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for
'sm_89'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 38 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for
'sm_89'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 38 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_'
 for 'sm_89'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 38 registers, 480 bytes cmem[0]
[5/8] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d
 -ccbin /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDS
bDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\"
 -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isys
tem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/min
iconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-pa
ckages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/py
thon3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS_
_ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=s
m_89 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3
--extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_
B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -
DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_
RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HA
LF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_N
O_BFLOAT162_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/cud
a/slstm_backward.cu -o slstm_backward.cuda.o
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelE
jjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_89'
ptxas info    : Function properties for _ZN50_GLOBAL__N__c11a27b6_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjj
jjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 40 registers, 400 bytes cmem[0]
[6/8] /home/e20037/miniconda/envs/xlstm/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -ccbin /h
ome/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1
GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND1
1_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include -isystem /home/
e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/e20037/miniconda/env
s/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/tor
ch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/envs/xlstm/include/python3.11 -
D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA
_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --com
piler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-de
vice-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -D
SLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTY
PE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_
CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERS
IONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT16
2_CONVERSIONS__ -std=c++17 -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/src/util/blas.cu
-o blas.cuda.o
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_89'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_89'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_89'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_89'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH
4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STD
LIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/t
orch/include -isystem /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isyste
m /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/include/TH -isystem /home/e20037/miniconda/envs/xlstm/lib/
python3.11/site-packages/torch/include/THC -isystem /home/e20037/miniconda/envs/xlstm/include -isystem /home/e20037/miniconda/env
s/xlstm/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_H
EADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__n
v_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECUR
RENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -
U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U
__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /home/e20037/miniconda/envs/xlstm/lib/python3.11/site-pack
ages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o
[8/8] /home/e20037/miniconda/envs/xlstm/bin/x86_64-conda-linux-gnu-c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_b
ackward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/home/e20037/miniconda/envs/xlstm/lib -lcublas
-L/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -lto
rch_python -L/home/e20037/miniconda/envs/xlstm/lib -lcudart -o slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.s
o
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.cus
tom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @conditional_decorator(
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.cus
tom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @conditional_decorator(
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.cus
tom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @conditional_decorator(
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.cus
tom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @conditional_decorator(
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.cus
tom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @conditional_decorator(
/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.cus
tom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @conditional_decorator(
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skippi
ng build step...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skippi
ng build step...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skippi
ng build step...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skippi
ng build step...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/e20037/miniconda/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['
-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLST
M_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DS
LSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM
_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATO
RS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_B
FLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80
,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=51
2', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat1
6', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '
-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CL
IPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HA
LF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__',
 '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skippi
ng build step...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Training dtype: torch.float32
xLSTMLMModel(
  (xlstm_block_stack): xLSTMBlockStack(
    (blocks): ModuleList(
      (0-2): 3 x mLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): mLSTMLayer(
          (proj_up): Linear(in_features=512, out_features=2048, bias=False)
          (q_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (k_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (v_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (conv1d): CausalConv1d(
            (conv): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          )
          (conv_act_fn): SiLU()
          (mlstm_cell): mLSTMCell(
            (igate): Linear(in_features=3072, out_features=4, bias=True)
            (fgate): Linear(in_features=3072, out_features=4, bias=True)
            (outnorm): MultiHeadLayerNorm()
          )
          (ogate_act_fn): SiLU()
          (proj_down): Linear(in_features=1024, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (3): sLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): sLSTMLayer(
          (conv1d): CausalConv1d(
            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
          )
          (conv_act_fn): SiLU()
          (fgate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (igate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (zgate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (ogate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (slstm_cell): sLSTMCell_cuda(function=slstm, hidden_size=512, num_heads=4)
          (group_norm): MultiHeadLayerNorm()
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (ffn_norm): LayerNorm()
        (ffn): GatedFeedForward(
          (proj_up): Linear(in_features=512, out_features=1408, bias=False)
          (proj_down): Linear(in_features=704, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (4-5): 2 x mLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): mLSTMLayer(
          (proj_up): Linear(in_features=512, out_features=2048, bias=False)
          (q_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (k_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (v_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (conv1d): CausalConv1d(
            (conv): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          )
          (conv_act_fn): SiLU()
          (mlstm_cell): mLSTMCell(
            (igate): Linear(in_features=3072, out_features=4, bias=True)
            (fgate): Linear(in_features=3072, out_features=4, bias=True)
            (outnorm): MultiHeadLayerNorm()
          )
          (ogate_act_fn): SiLU()
          (proj_down): Linear(in_features=1024, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (6): sLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): sLSTMLayer(
          (conv1d): CausalConv1d(
            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
          )
          (conv_act_fn): SiLU()
          (fgate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (igate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (zgate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (ogate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (slstm_cell): sLSTMCell_cuda(function=slstm, hidden_size=512, num_heads=4)
          (group_norm): MultiHeadLayerNorm()
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (ffn_norm): LayerNorm()
        (ffn): GatedFeedForward(
          (proj_up): Linear(in_features=512, out_features=1408, bias=False)
          (proj_down): Linear(in_features=704, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (7-8): 2 x mLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): mLSTMLayer(
          (proj_up): Linear(in_features=512, out_features=2048, bias=False)
          (q_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (k_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (v_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (conv1d): CausalConv1d(
            (conv): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          )
          (conv_act_fn): SiLU()
          (mlstm_cell): mLSTMCell(
            (igate): Linear(in_features=3072, out_features=4, bias=True)
            (fgate): Linear(in_features=3072, out_features=4, bias=True)
            (outnorm): MultiHeadLayerNorm()
          )
          (ogate_act_fn): SiLU()
          (proj_down): Linear(in_features=1024, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (9): sLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): sLSTMLayer(
          (conv1d): CausalConv1d(
            (conv): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
          )
          (conv_act_fn): SiLU()
          (fgate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (igate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (zgate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (ogate): LinearHeadwiseExpand(in_features=512, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trai
nable_bias=True, )
          (slstm_cell): sLSTMCell_cuda(function=slstm, hidden_size=512, num_heads=4)
          (group_norm): MultiHeadLayerNorm()
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (ffn_norm): LayerNorm()
        (ffn): GatedFeedForward(
          (proj_up): Linear(in_features=512, out_features=1408, bias=False)
          (proj_down): Linear(in_features=704, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (10-11): 2 x mLSTMBlock(
        (xlstm_norm): LayerNorm()
        (xlstm): mLSTMLayer(
          (proj_up): Linear(in_features=512, out_features=2048, bias=False)
          (q_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (k_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (v_proj): LinearHeadwiseExpand(in_features=1024, num_heads=256, expand_factor_up=1, bias=False, trainable_weight=True,
trainable_bias=True, )
          (conv1d): CausalConv1d(
            (conv): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
          )
          (conv_act_fn): SiLU()
          (mlstm_cell): mLSTMCell(
            (igate): Linear(in_features=3072, out_features=4, bias=True)
            (fgate): Linear(in_features=3072, out_features=4, bias=True)
            (outnorm): MultiHeadLayerNorm()
          )
          (ogate_act_fn): SiLU()
          (proj_down): Linear(in_features=1024, out_features=512, bias=False)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_blocks_norm): LayerNorm()
  )
  (token_embedding): Embedding(675, 512)
  (emb_dropout): Identity()
  (lm_head): Linear(in_features=512, out_features=675, bias=False)
)
Number of parameters: 20_083_784 (20.1M)
Preparing DataLoader...
Estimated number of steps: 39_686
Using /home/e20037/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...
No modifications detected for re-loaded extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0, skippi
ng build step...
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Enabling wandb logging for project: lmd_remigen_xlstm
Training:   0%|                                                                                      | 0/39686 [00:00<?, ?step/s]
wandb: Currently logged in as: haritha037 (haritha037-university-of-peradeniya). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.24.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/wandb/run-
20260118_190005-mgtbs4dr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_20260118-1856-xlstm_lmd_512d_8192ctx_12b
wandb:  View project at https://wandb.ai/haritha037-university-of-peradeniya/lmd_remigen_xlstm
wandb:  View run at https://wandb.ai/haritha037-university-of-peradeniya/lmd_remigen_xlstm/runs/mgtbs4dr
Training:   0%|                                                                                      | 0/39686 [00:00<?, ?step/s]
Ignore index: 1
Traceback (most recent call last):
  File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 776, in <mo
dule>
    main()
  File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 100, in mai
n
    run_training(config_paths)
  File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 322, in run
_training
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_i
mpl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_
forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_i
mpl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_lm_model.py", line 52, in forward
    x = self.xlstm_block_stack(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_i
mpl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_block_stack.py", line 120, in forward
    x = block(x, **kwargs)
        ^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_i
mpl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/xlstm_block.py", line 77, in forward
    x = x + self.xlstm(self.xlstm_norm(x), **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_i
mpl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/layer.py", line 116, in forward
    h_tilde_state = self.mlstm_cell(q=q, k=k, v=v)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_i
mpl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/cell.py", line 61, in forward
    h_state = self.backend_fn(
              ^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/backends.py", line 76, in parallel_stab
ilized_simple
    D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 2.79 GiB
 is free. Process 869539 has 890.00 MiB memory in use. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of
 the allocated memory 40.49 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but una
llocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation
for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 77
6, in <module>
[rank2]:     main()
[rank2]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 10
0, in main
[rank2]:     run_training(config_paths)
[rank2]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 32
2, in run_training
[rank2]:     outputs = model(inputs)
[rank2]:               ^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1636, in
forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1454, in
_run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_lm_model.py", line 52, in forward
[rank2]:     x = self.xlstm_block_stack(x)
[rank2]:         ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_block_stack.py", line 120, in forward
[rank2]:     x = block(x, **kwargs)
[rank2]:         ^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/xlstm_block.py", line 77, in forward
[rank2]:     x = x + self.xlstm(self.xlstm_norm(x), **kwargs)
[rank2]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/layer.py", line 116, in forwar
d
[rank2]:     h_tilde_state = self.mlstm_cell(q=q, k=k, v=v)
[rank2]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/cell.py", line 61, in forward
[rank2]:     h_state = self.backend_fn(
[rank2]:               ^^^^^^^^^^^^^^^^
[rank2]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/backends.py", line 76, in para
llel_stabilized_simple
[rank2]:     D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)
[rank2]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 2 has a total capacity of 47.37 GiB of which
 3.66 GiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 40.49 GiB is a
llocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting
 PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pyto
rch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 77
6, in <module>
[rank1]:     main()
[rank1]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 10
0, in main
[rank1]:     run_training(config_paths)
[rank1]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 32
2, in run_training
[rank1]:     outputs = model(inputs)
[rank1]:               ^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1636, in
forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1454, in
_run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_lm_model.py", line 52, in forward
[rank1]:     x = self.xlstm_block_stack(x)
[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_block_stack.py", line 120, in forward
[rank1]:     x = block(x, **kwargs)
[rank1]:         ^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/xlstm_block.py", line 77, in forward
[rank1]:     x = x + self.xlstm(self.xlstm_norm(x), **kwargs)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/layer.py", line 116, in forwar
d
[rank1]:     h_tilde_state = self.mlstm_cell(q=q, k=k, v=v)
[rank1]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/cell.py", line 61, in forward
[rank1]:     h_state = self.backend_fn(
[rank1]:               ^^^^^^^^^^^^^^^^
[rank1]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/backends.py", line 76, in para
llel_stabilized_simple
[rank1]:     D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)
[rank1]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 1 has a total capacity of 47.37 GiB of which
 3.66 GiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 40.49 GiB is a
llocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting
 PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pyto
rch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 77
6, in <module>
[rank0]:     main()
[rank0]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 10
0, in main
[rank0]:     run_training(config_paths)
[rank0]:   File "/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna/train-modified-2.py", line 32
2, in run_training
[rank0]:     outputs = model(inputs)
[rank0]:               ^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1636, in
forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1454, in
_run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_lm_model.py", line 52, in forward
[rank0]:     x = self.xlstm_block_stack(x)
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/xlstm_block_stack.py", line 120, in forward
[rank0]:     x = block(x, **kwargs)
[rank0]:         ^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/xlstm_block.py", line 77, in forward
[rank0]:     x = x + self.xlstm(self.xlstm_norm(x), **kwargs)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/layer.py", line 116, in forwar
d
[rank0]:     h_tilde_state = self.mlstm_cell(q=q, k=k, v=v)
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapp
ed_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_
impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/cell.py", line 61, in forward
[rank0]:     h_state = self.backend_fn(
[rank0]:               ^^^^^^^^^^^^^^^^
[rank0]:   File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/mlstm/backends.py", line 76, in para
llel_stabilized_simple
[rank0]:     D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which
 2.79 GiB is free. Process 869539 has 890.00 MiB memory in use. Including non-PyTorch memory, this process has 43.70 GiB memory i
n use. Of the allocated memory 40.49 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserve
d but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See docum
entation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Training:   0%|                                                                                      | 0/39686 [00:19<?, ?step/s]
Training:   0%|                                                                                      | 0/39686 [00:19<?, ?step/s]
W0118 19:00:20.816000 129724384171520 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3992943 closing signa
l SIGTERM
E0118 19:00:21.383000 129724384171520 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 1 (p
id: 3992944) of binary: /home/e20037/miniconda/envs/xlstm/bin/python3.11
Traceback (most recent call last):
  File "/home/e20037/miniconda/envs/xlstm/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1097, in launch_comma
nd
    multi_gpu_launcher(args)
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_lau
ncher
    distrib_run.run(args)
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/e20037/miniconda/envs/xlstm/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_ag
ent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
============================================================
train-modified-2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2026-01-18_19:00:20
  host      : ada
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3992945)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-18_19:00:20
  host      : ada
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3992944)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
(xlstm) e20037@ada:/scratch1/e20-fyp-xlstm-music-generation/e20fyptemp1/fyp-musicgen/repos/helibrunna$
